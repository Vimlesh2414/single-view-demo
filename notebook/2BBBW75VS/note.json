{
  "paragraphs": [
    {
      "text": "%md\n## Single view demo\n\n#### Goal\n\nDemonstrate how you can use Hive to get a single view of product by combining ETL/CRM data from EDW/DB, along with web traffic and social media data (collected using HDF)\n\n#### Steps\n\n1. Use Sqoop to import CRM/ERP data from DB/EDW into Hive\n2. Use HDF to import related tweets into Hive\n3. Use HDF to import simulated web traffic logs into Hive\n4. Use Hive to analyze tables to populate statistics\n5. Use Hive to correlate the data from multiple data sources\n\n\n#### Part 1: EDW Optimization\n\nDemonstrate how to bulk import retail data from EDW/RDBMS into Hive and then incrementally keep the Hive tables periodically updated",
      "dateUpdated": "Jan 13, 2016 3:39:08 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452692863906_1418901413",
      "id": "20160113-134743_1060998530",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eSingle view demo\u003c/h2\u003e\n\u003ch4\u003eGoal\u003c/h4\u003e\n\u003cp\u003eDemonstrate how you can use Hive to get a single view of product by combining ETL/CRM data from EDW/DB, along with web traffic and social media data (collected using HDF)\u003c/p\u003e\n\u003ch4\u003eSteps\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eUse Sqoop to import CRM/ERP data from DB/EDW into Hive\u003c/li\u003e\n\u003cli\u003eUse HDF to import related tweets into Hive\u003c/li\u003e\n\u003cli\u003eUse HDF to import simulated web traffic logs into Hive\u003c/li\u003e\n\u003cli\u003eUse Hive to analyze tables to populate statistics\u003c/li\u003e\n\u003cli\u003eUse Hive to correlate the data from multiple data sources\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4\u003ePart 1: EDW Optimization\u003c/h4\u003e\n\u003cp\u003eDemonstrate how to bulk import retail data from EDW/RDBMS into Hive and then incrementally keep the Hive tables periodically updated\u003c/p\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 1:47:43 PM",
      "dateStarted": "Jan 13, 2016 3:34:26 PM",
      "dateFinished": "Jan 13, 2016 3:34:27 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Pre-requisites\nBefore running this notebook:\n- run below as root to give zeppelin sudo priviledge\n```\necho \"zeppelin  ALL\u003d(ALL) NOPASSWD: ALL\" \u003e\u003e /etc/sudoers\n```\n- run below to enable zeppelin to log in to postgres\n```\necho \"host all all 127.0.0.1/32 md5\" \u003e\u003e /var/lib/pgsql/data/pg_hba.conf\n```",
      "dateUpdated": "Jan 13, 2016 9:29:28 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452692927804_-169433992",
      "id": "20160113-134847_777473592",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4\u003ePre-requisites\u003c/h4\u003e\n\u003cp\u003eBefore running this notebook:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003erun below as root to give zeppelin sudo priviledge\u003cpre\u003e\u003ccode\u003eecho \"zeppelin  ALL\u003d(ALL) NOPASSWD: ALL\" \u0026gt;\u0026gt; /etc/sudoers\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003erun below to enable zeppelin to log in to postgres\u003cpre\u003e\u003ccode\u003eecho \"host all all 127.0.0.1/32 md5\" \u0026gt;\u0026gt; /var/lib/pgsql/data/pg_hba.conf\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 1:48:47 PM",
      "dateStarted": "Jan 13, 2016 9:29:23 PM",
      "dateFinished": "Jan 13, 2016 9:29:26 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Restart postgres",
      "text": "%sh\nsudo service ambari stop\nsudo service postgresql stop\nsudo service postgresql start\nsudo service ambari start",
      "dateUpdated": "Jan 13, 2016 9:35:53 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452691976481_-1308856086",
      "id": "20160113-133256_428223579",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "Stopping Ganglia\n/etc/init.d/ambari: line 30: /etc/init.d/hdp-gmetad: No such file or directory\n/etc/init.d/ambari: line 31: /etc/init.d/hdp-gmond: No such file or directory\nStopping Nagios\n/etc/init.d/ambari: line 34: /etc/init.d/nagios: No such file or directory\nStopping Ambari server\nUsing python  /usr/bin/python2.6\nStopping ambari-server\nAmbari Server stopped\nStopping Ambari agent\nVerifying Python version compatibility...\nUsing python  /usr/bin/python2.6\nFound ambari-agent PID: 6626\ntput: unknown terminal \"unknown\"\nERROR: ambari-agent not running. Stale PID File at: /var/run/ambari-agent/ambari-agent.pid\ntput: unknown terminal \"unknown\"\nRemoving PID file at /var/run/ambari-agent/ambari-agent.pid\ntput: unknown terminal \"unknown\"\nambari-agent successfully stopped\ntput: unknown terminal \"unknown\"\nStopping postgresql service: [  OK  ]\r\nStarting postgresql service: [  OK  ]\r\nStarting Ambari...                                \nStarting Ambari server                                    [\u001b[32;01m  OK  \u001b[0m]\nStarting Ambari agent                                     [\u001b[33;01mWARNINGS\u001b[0m]\ntput: unknown terminal \"unknown\"\ntput: unknown terminal \"unknown\"\n"
      },
      "dateCreated": "Jan 13, 2016 1:32:56 PM",
      "dateStarted": "Jan 13, 2016 9:35:06 PM",
      "dateFinished": "Jan 13, 2016 9:35:37 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create zeppelin user in Postgres",
      "text": "%sh\nsudo -u postgres psql -c \"create database contoso;\"\nsudo -u postgres psql -c \"CREATE USER zeppelin WITH PASSWORD \u0027zeppelin\u0027;\"\nsudo -u postgres psql -c \"GRANT ALL PRIVILEGES ON DATABASE contoso to zeppelin;\"\nsudo -u postgres psql -c \"\\du\"",
      "dateUpdated": "Jan 13, 2016 1:54:08 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452691127380_1898051711",
      "id": "20160113-131847_335828946",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "could not change directory to \"/home/zeppelin\"\nERROR:  database \"contoso\" already exists\ncould not change directory to \"/home/zeppelin\"\nCREATE ROLE\ncould not change directory to \"/home/zeppelin\"\nGRANT\ncould not change directory to \"/home/zeppelin\"\n            List of roles\n Role name | Attributes  | Member of \n-----------+-------------+-----------\n ambari    |             | {}\n it1       |             | {}\n mapred    |             | {}\n postgres  | Superuser   | {}\n           : Create role   \n           : Create DB     \n zeppelin  |             | {}\n\n"
      },
      "dateCreated": "Jan 13, 2016 1:18:47 PM",
      "dateStarted": "Jan 13, 2016 1:33:36 PM",
      "dateFinished": "Jan 13, 2016 1:33:36 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Setup Sqoop for Postgres",
      "text": "%sh\nsudo wget https://jdbc.postgresql.org/download/postgresql-9.4.1207.jar -P /usr/hdp/current/sqoop-client/lib\nls -la /usr/hdp/current/sqoop-client/lib/postgres*",
      "dateUpdated": "Jan 13, 2016 1:54:43 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452692156170_1961618479",
      "id": "20160113-133556_476072266",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "--2016-01-13 13:36:48--  https://jdbc.postgresql.org/download/postgresql-9.4.1207.jar\nResolving jdbc.postgresql.org... 174.143.35.228\nConnecting to jdbc.postgresql.org|174.143.35.228|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 607093 (593K) [application/java-archive]\nSaving to: “/usr/hdp/current/sqoop-client/lib/postgresql-9.4.1207.jar”\n\n     0K .......... .......... .......... .......... ..........  8%  524K 1s\n    50K .......... .......... .......... .......... .......... 16% 1.19M 1s\n   100K .......... .......... .......... .......... .......... 25% 1.18M 1s\n   150K .......... .......... .......... .......... .......... 33% 1.02M 0s\n   200K .......... .......... .......... .......... .......... 42%  888K 0s\n   250K .......... .......... .......... .......... .......... 50% 1.21M 0s\n   300K .......... .......... .......... .......... .......... 59% 1.02M 0s\n   350K .......... .......... .......... .......... .......... 67% 1.33M 0s\n   400K .......... .......... .......... .......... .......... 75%  924K 0s\n   450K .......... .......... .......... .......... .......... 84%  735K 0s\n   500K .......... .......... .......... .......... .......... 92% 3.48M 0s\n   550K .......... .......... .......... .......... ..        100%  888K\u003d0.6s\n\n2016-01-13 13:36:49 (1002 KB/s) - “/usr/hdp/current/sqoop-client/lib/postgresql-9.4.1207.jar” saved [607093/607093]\n\n-rw-r--r-- 1 root root 607093 2015-12-22 20:23 /usr/hdp/current/sqoop-client/lib/postgresql-9.4.1207.jar\n"
      },
      "dateCreated": "Jan 13, 2016 1:35:56 PM",
      "dateStarted": "Jan 13, 2016 1:36:48 PM",
      "dateFinished": "Jan 13, 2016 1:36:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Pull latest code",
      "text": "%sh\ngit clone https://github.com/abajwa-hw/single-view-demo.git \nls single-view-demo\n",
      "dateUpdated": "Jan 13, 2016 1:55:55 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452692208681_1891270727",
      "id": "20160113-133648_2117254326",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "Initialized empty Git repository in /home/zeppelin/single-view-demo/.git/\ncontoso-psql.sql\ncreatelog-mysql.sh\ncreatelog-psql.sh\ndata\npom-22.xml\npom.xml\nREADME.md\nruntopology.sh\nscreenshots\nsingleview-mysql-advanced-23.md\nsingleview-mysql-basic-21.md\nsingleview-mysql-basic-22.md\nsingleview-mysql-basic-23.md\nsingleview-psql-advanced-23.md\nsrc\ntarget\n"
      },
      "dateCreated": "Jan 13, 2016 1:36:48 PM",
      "dateStarted": "Jan 13, 2016 1:55:55 PM",
      "dateFinished": "Jan 13, 2016 1:57:52 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Download retail (contoso) dataset",
      "text": "%sh\ncd /tmp\nwget https://www.dropbox.com/s/r70i8j1ujx4h7j8/data.zip\nunzip data.zip\nhead /tmp/data/FactSales.csv",
      "dateUpdated": "Jan 13, 2016 2:00:50 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452692486574_1677885040",
      "id": "20160113-134126_1230976042",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "Archive:  data.zip\n  inflating: data/DimAccount.csv     \n  inflating: data/DimChannel.csv     \n  inflating: data/DimCurrency.csv    \n  inflating: data/DimCustomer.csv    \n  inflating: data/DimDate.csv        \n  inflating: data/DimEmployee.csv    \n  inflating: data/DimEntity.csv      \n  inflating: data/DimGeography.csv   \n  inflating: data/DimMachine.csv     \n  inflating: data/DimOutage.csv      \n  inflating: data/DimProduct.csv     \n  inflating: data/DimProductCategory.csv  \n  inflating: data/DimProductSubcategory.csv  \n  inflating: data/DimPromotion.csv   \n  inflating: data/DimSalesTerritory.csv  \n  inflating: data/DimScenario.csv    \n  inflating: data/DimStore.csv       \n  inflating: data/FactExchangeRate.csv  \n  inflating: data/FactInventory.csv  \n  inflating: data/FactITMachine.csv  \n  inflating: data/FactITSLA.csv      \n  inflating: data/FactOnlineSales.csv  \n  inflating: data/FactSales.csv      \n  inflating: data/FactSalesQuota.csv  \n  inflating: data/FactStrategyPlan.csv  \nSalesKey,DateKey,channelKey,StoreKey,ProductKey,PromotionKey,CurrencyKey,UnitCost,UnitPrice,SalesQuantity,ReturnQuantity,ReturnAmount,DiscountQuantity,DiscountAmount,TotalCost,SalesAmount,ETLLoadID,LoadDate,UpdateDate\r\n1,2007-01-02 00:00:00,1,209,956,10,1,91.05,198,8,0,0,1,39.6,728.4,1544.4,1,2010-01-01 00:00:00,2010-01-01 00:00:00\r\n2,2007-02-12 00:00:00,4,308,766,2,1,10.15,19.9,4,0,0,1,0.995,40.6,78.605,1,2010-01-01 00:00:00,2010-01-01 00:00:00\r\n3,2008-01-24 00:00:00,1,156,1175,11,1,209.03,410,9,0,0,3,61.5,1881.27,3628.5,1,2010-01-01 00:00:00,2010-01-01 00:00:00\r\n4,2008-01-13 00:00:00,2,306,1429,10,1,132.9,289,8,0,0,1,57.8,1063.2,2254.2,1,2010-01-01 00:00:00,2010-01-01 00:00:00\r\n5,2008-01-22 00:00:00,2,306,1133,10,1,144.52,436.2,24,0,0,3,261.72,3468.48,10207.08,1,2010-01-01 00:00:00,2010-01-01 00:00:00\r\n6,2007-07-02 00:00:00,3,200,2365,3,1,183.94,399.99,36,0,0,10,399.99,6621.84,13999.65,1,2010-01-01 00:00:00,2010-01-01 00:00:00\r\n7,2007-11-19 00:00:00,4,310,1016,5,1,68.06,148,6,0,0,2,44.4,408.36,843.6,1,2010-01-01 00:00:00,2010-01-01 00:00:00\r\n8,2008-04-10 00:00:00,2,307,138,15,1,229.93,499.99,9,0,0,1,99.998,2069.37,4399.912,1,2010-01-01 00:00:00,2010-01-01 00:00:00\r\n9,2008-07-14 00:00:00,2,199,1731,12,1,33.32,72.45,24,0,0,5,36.225,799.68,1702.575,1,2010-01-01 00:00:00,2010-01-01 00:00:00\r\n"
      },
      "dateCreated": "Jan 13, 2016 1:41:26 PM",
      "dateStarted": "Jan 13, 2016 2:00:50 PM",
      "dateFinished": "Jan 13, 2016 2:01:14 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Import data into postgres",
      "text": "%sh\nexport PGPASSWORD\u003dzeppelin\n#run sql to create tables and import data from csv\npsql -U zeppelin -d contoso -h localhost -f ~/single-view-demo/contoso-psql.sql\n#list tables\npsql -U zeppelin -d contoso -h localhost -c \"\\dt\"",
      "dateUpdated": "Jan 13, 2016 2:11:24 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452693495201_1697768268",
      "id": "20160113-135815_1850996657",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "CREATE TABLE\n strategyplankey |       datekey       | entitykey | scenariokey | accountkey | currencykey | productcategorykey |   amount    | etlloadid |        loaddate         | updatedate \n-----------------+---------------------+-----------+-------------+------------+-------------+--------------------+-------------+-----------+-------------------------+------------\n               1 | 2007-03-01 00:00:00 |       644 |           1 |          4 |           1 |                  8 | 221811.3155 |         1 | 2009-08-30 22:13:30.947 | \n               2 | 2007-02-01 00:00:00 |       674 |           1 |          4 |           1 |                  2 |   41288.655 |         1 | 2009-08-30 22:13:30.947 | \n               3 | 2007-01-01 00:00:00 |       927 |           1 |          4 |           1 |                  1 |   3962.0845 |         1 | 2009-08-30 22:13:30.947 | \n               4 | 2007-01-01 00:00:00 |       840 |           1 |          4 |           1 |                  2 |   78481.346 |         1 | 2009-08-30 22:13:30.947 | \n               5 | 2007-01-01 00:00:00 |       666 |           1 |          4 |           1 |                  4 | 134826.4105 |         1 | 2009-08-30 22:13:30.947 | \n(5 rows)\n\nCREATE TABLE\n salesquotakey | channelkey | storekey | productkey |       datekey       | currencykey | scenariokey | salesquantityquota | salesamountquota | grossmarginquota | etlloadid |        loaddate         |       updatedate        \n---------------+------------+----------+------------+---------------------+-------------+-------------+--------------------+------------------+------------------+-----------+-------------------------+-------------------------\n             1 |          1 |      169 |       2077 | 2007-02-01 00:00:00 |           1 |           1 |                  8 |          769.923 |          162.103 |         1 | 2010-01-19 01:29:13.893 | 2010-01-19 01:29:13.893\n             2 |          1 |      232 |       1122 | 2007-01-01 00:00:00 |           1 |           1 |                  8 |             2656 |          1434.56 |         1 | 2010-01-19 01:29:13.893 | 2010-01-19 01:29:13.893\n             3 |          1 |      128 |       1270 | 2008-11-01 00:00:00 |           1 |           1 |                 13 |            88.96 |            42.94 |         1 | 2010-01-19 01:29:13.893 | 2010-01-19 01:29:13.893\n             4 |          1 |      190 |       2156 | 2008-05-01 00:00:00 |           1 |           1 |                 10 |             1490 |            730.4 |         1 | 2010-01-19 01:29:13.893 | 2010-01-19 01:29:13.893\n             5 |          3 |      200 |       2023 | 2009-12-01 00:00:00 |           1 |           1 |                104 |         10198.98 |          4897.06 |         1 | 2010-01-19 01:29:13.893 | 2010-01-19 01:29:13.893\n(5 rows)\n\nCREATE TABLE\n saleskey |       datekey       | channelkey | storekey | productkey | promotionkey | currencykey | unitcost | unitprice | salesquantity | returnquantity | returnamount | discountquantity | discountamount | totalcost | salesamount | etlloadid |      loaddate       |     updatedate      \n----------+---------------------+------------+----------+------------+--------------+-------------+----------+-----------+---------------+----------------+--------------+------------------+----------------+-----------+-------------+-----------+---------------------+---------------------\n        1 | 2007-01-02 00:00:00 |          1 |      209 |        956 |           10 |           1 |    91.05 |       198 |             8 |              0 |            0 |                1 |           39.6 |     728.4 |      1544.4 |         1 | 2010-01-01 00:00:00 | 2010-01-01 00:00:00\n        2 | 2007-02-12 00:00:00 |          4 |      308 |        766 |            2 |           1 |    10.15 |      19.9 |             4 |              0 |            0 |                1 |          0.995 |      40.6 |      78.605 |         1 | 2010-01-01 00:00:00 | 2010-01-01 00:00:00\n        3 | 2008-01-24 00:00:00 |          1 |      156 |       1175 |           11 |           1 |   209.03 |       410 |             9 |              0 |            0 |                3 |           61.5 |   1881.27 |      3628.5 |         1 | 2010-01-01 00:00:00 | 2010-01-01 00:00:00\n        4 | 2008-01-13 00:00:00 |          2 |      306 |       1429 |           10 |           1 |    132.9 |       289 |             8 |              0 |            0 |                1 |           57.8 |    1063.2 |      2254.2 |         1 | 2010-01-01 00:00:00 | 2010-01-01 00:00:00\n        5 | 2008-01-22 00:00:00 |          2 |      306 |       1133 |           10 |           1 |   144.52 |     436.2 |            24 |              0 |            0 |                3 |         261.72 |   3468.48 |    10207.08 |         1 | 2010-01-01 00:00:00 | 2010-01-01 00:00:00\n(5 rows)\n\nCREATE TABLE\n onlinesaleskey |       datekey       | storekey | productkey | promotionkey | currencykey | customerkey | salesordernumber | salesorderlinenumber | salesquantity | salesamount | returnquantity | returnamount | discountquantity | discountamount | totalcost | unitcost | unitprice | etlloadid | loaddate | updatedate \n----------------+---------------------+----------+------------+--------------+-------------+-------------+------------------+----------------------+---------------+-------------+----------------+--------------+------------------+----------------+-----------+----------+-----------+-----------+----------+------------\n       19560484 | 2007-01-01 00:00:00 |      306 |        782 |           10 |           1 |         333 | 20070101311332   |                    1 |             1 |       10.36 |              0 |            0 |                1 |           2.59 |       6.6 |      6.6 |     12.95 |           |          | \n       19560485 | 2007-01-01 00:00:00 |      306 |        782 |           10 |           1 |         334 | 20070101311333   |                    1 |             1 |       10.36 |              0 |            0 |                1 |           2.59 |       6.6 |      6.6 |     12.95 |           |          | \n       19560486 | 2007-01-01 00:00:00 |      306 |        782 |           10 |           1 |         335 | 20070101311334   |                    1 |             1 |       10.36 |              0 |            0 |                1 |           2.59 |       6.6 |      6.6 |     12.95 |           |          | \n       19560487 | 2007-01-01 00:00:00 |      306 |        782 |           10 |           1 |         336 | 20070101311335   |                    1 |             1 |       10.36 |              0 |            0 |                1 |           2.59 |       6.6 |      6.6 |     12.95 |           |          | \n       19560488 | 2007-01-01 00:00:00 |      306 |        782 |           10 |           1 |         337 | 20070101311336   |                    1 |             1 |       10.36 |              0 |            0 |                1 |           2.59 |       6.6 |      6.6 |     12.95 |           |          | \n(5 rows)\n\nCREATE TABLE\n itslakey |       datekey       | storekey | machinekey | outagekey |   outagestarttime   |    outageendtime    | downtime | etlloadid |      loaddate       |     updatedate      \n----------+---------------------+----------+------------+-----------+---------------------+---------------------+----------+-----------+---------------------+---------------------\n        1 | 2007-05-27 00:00:00 |       18 |        177 |       423 | 2007-05-27 03:23:00 | 2007-05-27 03:27:00 |        4 |         1 | 2007-05-27 00:00:00 | 2007-05-27 00:00:00\n        2 | 2007-05-04 00:00:00 |      168 |       1348 |       522 | 2007-05-04 17:39:00 | 2007-05-04 18:04:00 |       25 |         1 | 2007-05-04 00:00:00 | 2007-05-04 00:00:00\n        3 | 2007-09-29 00:00:00 |      143 |       1103 |       577 | 2007-09-29 03:41:00 | 2007-09-29 17:30:00 |      829 |         1 | 2007-09-29 00:00:00 | 2007-09-29 00:00:00\n        4 | 2007-05-13 00:00:00 |       16 |        160 |       501 | 2007-05-13 14:07:00 | 2007-05-13 14:58:00 |       51 |         1 | 2007-05-13 00:00:00 | 2007-05-13 00:00:00\n        5 | 2007-06-06 00:00:00 |      116 |        827 |       463 | 2007-06-06 18:50:00 | 2007-06-06 19:15:00 |       25 |         1 | 2007-06-06 00:00:00 | 2007-06-06 00:00:00\n(5 rows)\n\nCREATE TABLE\n itmachinekey | machinekey |       datekey       | costamount |        costtype         | etlloadid |        loaddate         |       updatedate        \n--------------+------------+---------------------+------------+-------------------------+-----------+-------------------------+-------------------------\n            1 |          1 | 2007-01-01 00:00:00 |        500 | Annual Maintenance Cost |         1 | 2009-08-24 23:59:22.373 | 2009-08-24 23:59:22.373\n            2 |          1 | 2008-01-01 00:00:00 |        700 | Annual Maintenance Cost |         1 | 2009-08-24 23:59:22.373 | 2009-08-24 23:59:22.373\n            3 |          1 | 2009-01-01 00:00:00 |       1200 | Annual Maintenance Cost |         1 | 2009-08-24 23:59:22.373 | 2009-08-24 23:59:22.373\n            4 |          2 | 2007-01-01 00:00:00 |        500 | Annual Maintenance Cost |         1 | 2009-08-24 23:59:22.373 | 2009-08-24 23:59:22.373\n            5 |          2 | 2008-01-01 00:00:00 |        700 | Annual Maintenance Cost |         1 | 2009-08-24 23:59:22.373 | 2009-08-24 23:59:22.373\n(5 rows)\n\nCREATE TABLE\n inventorykey |       datekey       | storekey | productkey | currencykey | onhandquantity | onorderquantity | safetystockquantity | unitcost | daysinstock | mindayinstock | maxdayinstock | aging | etlloadid |      loaddate       |     updatedate      \n--------------+---------------------+----------+------------+-------------+----------------+-----------------+---------------------+----------+-------------+---------------+---------------+-------+-----------+---------------------+---------------------\n            1 | 2008-02-09 00:00:00 |      308 |       2086 |           1 |             16 |               3 |                   9 |   403.53 |          12 |            26 |           109 |     7 |         1 | 2010-01-01 00:00:00 | 2010-01-01 00:00:00\n            2 | 2007-06-09 00:00:00 |      239 |        643 |           1 |             21 |               1 |                   9 |    77.72 |          24 |            21 |            95 |     7 |         1 | 2010-01-01 00:00:00 | 2010-01-01 00:00:00\n            3 | 2009-01-31 00:00:00 |      205 |         18 |           1 |             17 |               1 |                   6 |    50.56 |          48 |            57 |            94 |     7 |         1 | 2010-01-01 00:00:00 | 2010-01-01 00:00:00\n            4 | 2007-06-02 00:00:00 |      199 |       1587 |           1 |             21 |               1 |                  90 |     8.27 |          59 |            15 |           118 |     7 |         1 | 2010-01-01 00:00:00 | 2010-01-01 00:00:00\n            5 | 2009-11-21 00:00:00 |       29 |       2269 |           1 |             45 |              13 |                  12 |    15.29 |          24 |            54 |            60 |     7 |         1 | 2010-01-01 00:00:00 | 2010-01-01 00:00:00\n(5 rows)\n\nCREATE TABLE\n exchangeratekey | currencykey |       datekey       | averagerate | endofdayrate | etlloadid |      loaddate       |     updatedate      \n-----------------+-------------+---------------------+-------------+--------------+-----------+---------------------+---------------------\n               1 |           2 | 2007-01-01 00:00:00 |       363.7 |        359.4 |         1 | 2009-07-01 00:00:00 | 2009-07-01 00:00:00\n               2 |           2 | 2007-02-01 00:00:00 |         356 |        353.6 |         1 | 2009-07-01 00:00:00 | 2009-07-01 00:00:00\n               3 |           2 | 2007-03-01 00:00:00 |       358.6 |        362.1 |         1 | 2009-07-01 00:00:00 | 2009-07-01 00:00:00\n               4 |           2 | 2007-04-01 00:00:00 |       363.3 |          357 |         1 | 2009-07-01 00:00:00 | 2009-07-01 00:00:00\n               5 |           2 | 2007-05-01 00:00:00 |       353.8 |        347.9 |         1 | 2009-07-01 00:00:00 | 2009-07-01 00:00:00\n(5 rows)\n\nCREATE TABLE\n storekey | geographykey | storemanager | storetype |         storename          |      storedescription      | status |      opendate       | closedate | entitykey | zipcode | zipcodeextension |  storephone  |   storefax   | closereason | employeecount | sellingareasize |   lastremodeldate   | etlloadid |      somedate1      |      somedate2      |      loaddate       |     updatedate      \n----------+--------------+--------------+-----------+----------------------------+----------------------------+--------+---------------------+-----------+-----------+---------+------------------+--------------+--------------+-------------+---------------+-----------------+---------------------+-----------+---------------------+---------------------+---------------------+---------------------\n        1 |          693 |           35 | Store     | Contoso Seattle No.1 Store | Contoso Seattle No.1 Store | On     | 2004-04-12 00:00:00 |           |       635 | 97001   | 97001            | 320-555-0195 | 320-555-0195 |             |            17 |             462 | 2009-06-16 00:00:00 |         1 | 2009-06-05 00:00:00 | 2009-06-05 00:00:00 | 2009-06-05 00:00:00 | 2009-06-05 00:00:00\n        2 |          693 |           35 | Store     | Contoso Seattle No.2 Store | Contoso Seattle No.2 Store | On     | 2004-02-14 00:00:00 |           |       636 | 97001   | 97002            | 150-555-0189 | 150-555-0189 |             |            25 |             700 | 2009-06-17 00:00:00 |         1 | 2009-06-05 00:00:00 | 2009-06-05 00:00:00 | 2009-06-05 00:00:00 | 2009-06-05 00:00:00\n        3 |          856 |           36 | Store     | Contoso Kennewick Store    | Contoso Kennewick Store    | On     | 2004-02-12 00:00:00 |           |       934 | 97001   | 97003            | 212-555-0187 | 212-555-0187 |             |            26 |             680 | 2009-06-18 00:00:00 |         1 | 2008-11-21 00:00:00 | 2008-11-21 00:00:00 | 2008-11-21 00:00:00 | 2008-11-21 00:00:00\n        4 |          424 |           37 | Store     | Contoso Bellevue Store     | Contoso Bellevue Store     | On     | 2004-03-01 00:00:00 |           |       638 | 97001   | 97004            | 612-555-0100 | 612-555-0100 |             |            19 |             455 | 2009-06-16 00:00:00 |         1 | 2009-07-01 00:00:00 | 2009-07-01 00:00:00 | 2009-07-01 00:00:00 | 2009-07-01 00:00:00\n        5 |          677 |           38 | Store     | Contoso Redmond Store      | Contoso Redmond Store      | On     | 2004-04-02 00:00:00 |           |       639 | 97001   | 97005            | 612-555-0100 | 612-555-0100 |             |            33 |             560 | 2009-06-17 00:00:00 |         1 | 2009-06-13 00:00:00 | 2009-06-13 00:00:00 | 2009-06-13 00:00:00 | 2009-06-13 00:00:00\n(5 rows)\n\nCREATE TABLE\n salesterritorykey | geographykey | salesterritorylabel | salesterritoryname | salesterritoryregion | salesterritorycountry | salesterritorygroup | salesterritorylevel | salesterritorymanager |        startdate        | enddate | status  | etlloadid |      loaddate       |     updatedate      \n-------------------+--------------+---------------------+--------------------+----------------------+-----------------------+---------------------+---------------------+-----------------------+-------------------------+---------+---------+-----------+---------------------+---------------------\n                 1 |          693 | 010112001           | Seattle            | Washington           | United States         | North America       | 4                   |                    35 | 2009-09-29 02:48:10.587 |         | Current |         1 | 2009-08-01 00:00:00 | 2009-08-01 00:00:00\n                 2 |          856 | 010112002           | Kennewick          | Washington           | United States         | North America       | 4                   |                    36 | 2009-09-29 02:48:10.587 |         | Current |         1 | 2009-08-01 00:00:00 | 2009-08-01 00:00:00\n                 3 |          424 | 010112003           | Bellevue           | Washington           | United States         | North America       | 4                   |                    37 | 2009-09-29 02:48:10.587 |         | Current |         1 | 2009-08-01 00:00:00 | 2009-08-01 00:00:00\n                 4 |          677 | 010112004           | Redmond            | Washington           | United States         | North America       | 4                   |                    38 | 2009-09-29 02:48:10.587 |         | Current |         1 | 2009-08-01 00:00:00 | 2009-08-01 00:00:00\n                 5 |          575 | 010112005           | Yakima             | Washington           | United States         | North America       | 4                   |                    39 | 2009-09-29 02:48:10.587 |         | Current |         1 | 2009-08-01 00:00:00 | 2009-08-01 00:00:00\n(5 rows)\n\n               List of relations\n Schema |       Name        | Type  |  Owner   \n--------+-------------------+-------+----------\n public | dimsalesterritory | table | zeppelin\n public | dimstore          | table | zeppelin\n public | factexchangerate  | table | zeppelin\n public | factinventory     | table | zeppelin\n public | factitmachine     | table | zeppelin\n public | factitsla         | table | zeppelin\n public | factonlinesales   | table | zeppelin\n public | factsales         | table | zeppelin\n public | factsalesquota    | table | zeppelin\n public | factstrategyplan  | table | zeppelin\n(10 rows)\n\n"
      },
      "dateCreated": "Jan 13, 2016 1:58:15 PM",
      "dateStarted": "Jan 13, 2016 2:11:24 PM",
      "dateFinished": "Jan 13, 2016 2:13:47 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "List tables from sqoop",
      "text": "%sh\nsqoop list-tables --connect jdbc:postgresql://localhost:5432/contoso --username zeppelin --password zeppelin -- schema contoso ",
      "dateUpdated": "Jan 13, 2016 2:14:18 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452694284511_-957637824",
      "id": "20160113-141124_1982574845",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "Warning: /usr/hdp/2.3.2.0-2950/accumulo does not exist! Accumulo imports will fail.\nPlease set $ACCUMULO_HOME to the root of your Accumulo installation.\n16/01/13 14:14:20 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6.2.3.2.0-2950\n16/01/13 14:14:20 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.\n16/01/13 14:14:20 INFO manager.SqlManager: Using default fetchSize of 1000\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/zookeeper/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\nfactstrategyplan\nfactsalesquota\nfactsales\nfactonlinesales\nfactitsla\nfactitmachine\nfactinventory\nfactexchangerate\ndimstore\ndimsalesterritory\n"
      },
      "dateCreated": "Jan 13, 2016 2:11:24 PM",
      "dateStarted": "Jan 13, 2016 2:14:18 PM",
      "dateFinished": "Jan 13, 2016 2:14:21 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Make sure hive is started and Up",
      "text": "%sh\nexport SERVICE\u003dHIVE\nexport PASSWORD\u003dadmin\nexport AMBARI_HOST\u003dlocalhost\nexport CLUSTER\u003dSandbox\n\ncurl -u admin:$PASSWORD -i -H \u0027X-Requested-By: ambari\u0027 -X PUT -d \u0027{\"RequestInfo\": {\"context\" :\"Start Hive via REST\"}, \"Body\": {\"ServiceInfo\": {\"state\": \"STARTED\"}}}\u0027  http://$AMBARI_HOST:8080/api/v1/clusters/$CLUSTER/services/$SERVICE",
      "dateUpdated": "Jan 13, 2016 2:34:26 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452695067865_1445807000",
      "id": "20160113-142427_1944290859",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    98      0   153k --:--:-- --:--:-- --:--:--  153k\r  0     0    0     0    0    98      0  11805 --:--:-- --:--:-- --:--:--     0\nHTTP/1.1 200 OK\r\nUser: admin\r\nSet-Cookie: AMBARISESSIONID\u003d1pi4pyki2j8pgd4wee8korl6e;Path\u003d/;HttpOnly\r\nExpires: Thu, 01 Jan 1970 00:00:00 GMT\r\nContent-Type: text/plain\r\nContent-Length: 0\r\nServer: Jetty(8.1.17.v20150415)\r\n\r\n"
      },
      "dateCreated": "Jan 13, 2016 2:24:27 PM",
      "dateStarted": "Jan 13, 2016 2:34:26 PM",
      "dateFinished": "Jan 13, 2016 2:34:26 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "bulk load Tables from Psql into Hive",
      "text": "%sh\nsqoop import-all-tables --username zeppelin --password zeppelin --connect jdbc:postgresql://localhost:5432/contoso  --hive-import  --direct",
      "dateUpdated": "Jan 13, 2016 2:35:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452694458755_-702905048",
      "id": "20160113-141418_435147104",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "16/01/13 14:35:46 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6.2.3.2.0-2950\n16/01/13 14:35:46 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.\n16/01/13 14:35:46 INFO tool.BaseSqoopTool: Using Hive-specific delimiters for output. You can override\n16/01/13 14:35:46 INFO tool.BaseSqoopTool: delimiters with --fields-terminated-by, etc.\n16/01/13 14:35:46 INFO manager.SqlManager: Using default fetchSize of 1000\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/zookeeper/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n16/01/13 14:35:46 INFO tool.CodeGenTool: Beginning code generation\n16/01/13 14:35:46 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM \"factstrategyplan\" AS t LIMIT 1\n16/01/13 14:35:46 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/hdp/2.3.2.0-2950/hadoop-mapreduce\nNote: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/factstrategyplan.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n16/01/13 14:35:48 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/factstrategyplan.jar\n16/01/13 14:35:48 INFO manager.DirectPostgresqlManager: Beginning psql fast path import\n16/01/13 14:35:48 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM \"factstrategyplan\" AS t LIMIT 1\n16/01/13 14:35:48 INFO manager.DirectPostgresqlManager: Copy command is COPY (SELECT \"strategyplankey\", \"datekey\", \"entitykey\", \"scenariokey\", \"accountkey\", \"currencykey\", \"productcategorykey\", \"amount\", \"etlloadid\", \"loaddate\", \"updatedate\" FROM \"factstrategyplan\" WHERE 1\u003d1) TO STDOUT WITH DELIMITER E\u0027\\1\u0027 CSV ;\n16/01/13 14:35:48 INFO manager.DirectPostgresqlManager: Performing import of table factstrategyplan from database contoso\n16/01/13 14:36:01 INFO manager.DirectPostgresqlManager: Transfer loop complete.\n16/01/13 14:36:01 INFO manager.DirectPostgresqlManager: Transferred 233.7275 MB in 12.3766 seconds (18.8846 MB/sec)\n16/01/13 14:36:01 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM \"factstrategyplan\" AS t LIMIT 1\n16/01/13 14:36:01 WARN hive.TableDefWriter: Column datekey had to be cast to a less precise type in Hive\n16/01/13 14:36:01 WARN hive.TableDefWriter: Column loaddate had to be cast to a less precise type in Hive\n16/01/13 14:36:01 WARN hive.TableDefWriter: Column updatedate had to be cast to a less precise type in Hive\n16/01/13 14:36:01 INFO hive.HiveImport: Loading uploaded data into Hive\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 1.561 seconds\nLoading data to table default.factstrategyplan\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/factstrategyplan/part-m-00000_copy_1\u0027: User does not belong to hdfs\nTable default.factstrategyplan stats: [numFiles\u003d2, totalSize\u003d490162114]\nOK\nTime taken: 6.47 seconds\nNote: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/factsalesquota.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 0.185 seconds\nLoading data to table default.factsalesquota\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/factsalesquota/part-m-00000_copy_1\u0027: User does not belong to hdfs\nTable default.factsalesquota stats: [numFiles\u003d2, totalSize\u003d1674715474]\nOK\nTime taken: 6.345 seconds\nNote: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/factsales.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 0.158 seconds\nLoading data to table default.factsales\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/factsales/part-m-00000_copy_1\u0027: User does not belong to hdfs\nTable default.factsales stats: [numFiles\u003d2, totalSize\u003d833134488]\nOK\nTime taken: 6.319 seconds\nNote: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/factonlinesales.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 0.329 seconds\nLoading data to table default.factonlinesales\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/factonlinesales/part-m-00000_copy_1\u0027: User does not belong to hdfs\nTable default.factonlinesales stats: [numFiles\u003d2, totalSize\u003d2658422744]\nOK\nTime taken: 6.349 seconds\nNote: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/factitsla.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 0.149 seconds\nLoading data to table default.factitsla\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/factitsla/part-m-00000_copy_1\u0027: User does not belong to hdfs\nTable default.factitsla stats: [numFiles\u003d2, totalSize\u003d1202874]\nOK\nTime taken: 6.231 seconds\nNote: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/factitmachine.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 0.144 seconds\nLoading data to table default.factitmachine\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/factitmachine/part-m-00000_copy_1\u0027: User does not belong to hdfs\nTable default.factitmachine stats: [numFiles\u003d2, totalSize\u003d5108034]\nOK\nTime taken: 8.529 seconds\nNote: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/factinventory.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 7.034 seconds\nLoading data to table default.factinventory\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/factinventory/part-m-00000\u0027: User does not belong to hdfs\nTable default.factinventory stats: [numFiles\u003d1, totalSize\u003d837566319]\nOK\nTime taken: 2.174 seconds\nNote: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/factexchangerate.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 6.252 seconds\nLoading data to table default.factexchangerate\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/factexchangerate/part-m-00000\u0027: User does not belong to hdfs\nTable default.factexchangerate stats: [numFiles\u003d1, totalSize\u003d64207]\nOK\nTime taken: 2.057 seconds\nNote: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/dimstore.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 6.858 seconds\nLoading data to table default.dimstore\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/dimstore/part-m-00000\u0027: User does not belong to hdfs\nTable default.dimstore stats: [numFiles\u003d1, totalSize\u003d74041]\nOK\nTime taken: 2.235 seconds\nNote: /tmp/sqoop-zeppelin/compile/9c13ea24393e8712e8e6d361e29b57e7/dimsalesterritory.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 6.5 seconds\nLoading data to table default.dimsalesterritory\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/dimsalesterritory/part-m-00000\u0027: User does not belong to hdfs\nTable default.dimsalesterritory stats: [numFiles\u003d1, totalSize\u003d37551]\nOK\nTime taken: 1.917 seconds\n"
      },
      "dateCreated": "Jan 13, 2016 2:14:18 PM",
      "dateStarted": "Jan 13, 2016 2:35:44 PM",
      "dateFinished": "Jan 13, 2016 2:41:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThe above may run for a 5-10 minutes, but you can track the jobs using the Resource Manager UI e.g. [http://sandbox.hortonworks.com:8088/cluster](http://sandbox.hortonworks.com:8088/cluster)",
      "dateUpdated": "Jan 13, 2016 2:38:31 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452694720308_80426744",
      "id": "20160113-141840_578470232",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eThe above may run for a 5-10 minutes, but you can track the jobs using the Resource Manager UI e.g. \u003ca href\u003d\"http://sandbox.hortonworks.com:8088/cluster\"\u003ehttp://sandbox.hortonworks.com:8088/cluster\u003c/a\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 2:18:40 PM",
      "dateStarted": "Jan 13, 2016 2:38:28 PM",
      "dateFinished": "Jan 13, 2016 2:38:28 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Confirm Staging tables created in hive (text format)",
      "text": "%hive\nshow tables",
      "dateUpdated": "Jan 13, 2016 2:45:42 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "tab_name",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "tab_name",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452695332731_-1432713536",
      "id": "20160113-142852_416527267",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "tab_name\ndimsalesterritory\t\ndimstore\t\nfactexchangerate\t\nfactinventory\t\nfactitmachine\t\nfactitsla\t\nfactonlinesales\t\nfactsales\t\nfactsalesquota\t\nfactstrategyplan\t\nsample_07\t\nsample_08\t\n"
      },
      "dateCreated": "Jan 13, 2016 2:28:52 PM",
      "dateStarted": "Jan 13, 2016 2:43:37 PM",
      "dateFinished": "Jan 13, 2016 2:43:41 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create final table for FactSales (ORC format)",
      "text": "%hive\nCREATE TABLE `factsales_final` (\n`SalesKey` int ,\n`DateKey` timestamp ,  \n`channelKey` int ,  \n`StoreKey` int,\n`ProductKey` int,\n`PromotionKey` int,\n`CurrencyKey` int,\n`UnitCost` float,\n`UnitPrice` float,\n`SalesQuantity` int , \n`ReturnQuantity` int,\n`ReturnAmount` float,\n`DiscountQuantity` int,\n`DiscountAmount` float,\n`TotalCost` float,\n`SalesAmount` float,\n`ETLLoadID` int,\n`LoadDate` timestamp , \n`UpdateDate` timestamp \n )\nclustered by (saleskey) into 7 buckets\nstored as orc\nTBLPROPERTIES (\u0027transactional\u0027\u003d\u0027true\u0027)",
      "dateUpdated": "Jan 13, 2016 2:47:23 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452696217466_-888442151",
      "id": "20160113-144337_1561070436",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 2:43:37 PM",
      "dateStarted": "Jan 13, 2016 2:47:23 PM",
      "dateFinished": "Jan 13, 2016 2:47:26 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "populate FactSales final table (from staging)",
      "text": "%hive\ninsert into factsales_final select * from factsales",
      "dateUpdated": "Jan 13, 2016 2:48:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452696443249_-317769231",
      "id": "20160113-144723_1682335578",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 2:47:23 PM",
      "dateStarted": "Jan 13, 2016 2:48:29 PM",
      "dateFinished": "Jan 13, 2016 2:50:05 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n#### Incremental import of data into Hive from RDBMS\n\nNow that we did the one time bulk import, next we will setup an incremental sqoop job\n\nFirst we create password file containing it1 user\u0027s password in HDFS. This is done to allow invocations of the job to be automated/scheduled (without having to manually pass the password )",
      "dateUpdated": "Jan 13, 2016 2:52:58 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452696502670_1134965995",
      "id": "20160113-144822_432127701",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4\u003eIncremental import of data into Hive from RDBMS\u003c/h4\u003e\n\u003cp\u003eNow that we did the one time bulk import, next we will setup an incremental sqoop job\u003c/p\u003e\n\u003cp\u003eFirst we create password file containing it1 user\u0027s password in HDFS. This is done to allow invocations of the job to be automated/scheduled (without having to manually pass the password )\u003c/p\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 2:48:22 PM",
      "dateStarted": "Jan 13, 2016 2:52:56 PM",
      "dateFinished": "Jan 13, 2016 2:52:56 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\n# use -n to ensure newline is not added\necho -n \"zeppelin\" \u003e .password\nhadoop fs -put .password /user/zeppelin/\nrm .password",
      "dateUpdated": "Jan 13, 2016 2:53:36 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452696776580_402002371",
      "id": "20160113-145256_1142575263",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Jan 13, 2016 2:52:56 PM",
      "dateStarted": "Jan 13, 2016 2:53:36 PM",
      "dateFinished": "Jan 13, 2016 2:53:39 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCreate incremental import sqoop job for factsales table and point it as below: \n  - --table: table the job is for (i.e. factsales)\n  - --password-file: the HDFS location of the password file\n  - --incremental: lastmodified (we want to use lastmodified logic to find delta records)\n  - --check-column: specify which column that will be used to determine which delta records will be picked up (in this case, records whose updatedate column value is later than 2015-01-01 will be picked up)\n  - see [Sqoop documentation on incremental imports](https://sqoop.apache.org/docs/1.4.2/SqoopUserGuide.html#_incremental_imports) for more details\n",
      "dateUpdated": "Jan 13, 2016 2:54:56 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452696816210_942836731",
      "id": "20160113-145336_1316404593",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eCreate incremental import sqoop job for factsales table and point it as below:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026ndash;table: table the job is for (i.e. factsales)\u003c/li\u003e\n\u003cli\u003e\u0026ndash;password-file: the HDFS location of the password file\u003c/li\u003e\n\u003cli\u003e\u0026ndash;incremental: lastmodified (we want to use lastmodified logic to find delta records)\u003c/li\u003e\n\u003cli\u003e\u0026ndash;check-column: specify which column that will be used to determine which delta records will be picked up (in this case, records whose updatedate column value is later than 2015-01-01 will be picked up)\u003c/li\u003e\n\u003cli\u003esee \u003ca href\u003d\"https://sqoop.apache.org/docs/1.4.2/SqoopUserGuide.html#_incremental_imports\"\u003eSqoop documentation on incremental imports\u003c/a\u003e for more details\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 2:53:36 PM",
      "dateStarted": "Jan 13, 2016 2:54:38 PM",
      "dateFinished": "Jan 13, 2016 2:54:38 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create incremental sqoop job",
      "text": "%sh\nsqoop job -create factsales -- import --verbose --connect \u0027jdbc:postgresql://localhost:5432/contoso\u0027 --table factsales -username zeppelin --password-file hdfs://sandbox.hortonworks.com:8020/user/zeppelin/.password --check-column updatedate --incremental lastmodified --last-value \u00272015-01-01\u0027 --hive-import  --direct",
      "dateUpdated": "Jan 13, 2016 2:58:21 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "tableHide": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452696864545_1318244389",
      "id": "20160113-145424_721947841",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "Warning: /usr/hdp/2.3.2.0-2950/accumulo does not exist! Accumulo imports will fail.\nPlease set $ACCUMULO_HOME to the root of your Accumulo installation.\n16/01/13 14:56:02 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6.2.3.2.0-2950\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/zookeeper/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n16/01/13 14:56:03 DEBUG tool.BaseSqoopTool: Enabled debug logging.\n16/01/13 14:56:03 DEBUG password.FilePasswordLoader: Fetching password from specified path: hdfs://sandbox.hortonworks.com:8020/user/zeppelin/.password\n16/01/13 14:56:04 INFO tool.BaseSqoopTool: Using Hive-specific delimiters for output. You can override\n16/01/13 14:56:04 INFO tool.BaseSqoopTool: delimiters with --fields-terminated-by, etc.\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Creating job: factsales\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property sqoop.tool with class schema \u003d\u003e import\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property sqoop.tool with class schema\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property sqoop.property.set.id with class schema \u003d\u003e 0\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property sqoop.property.set.id with class schema\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting bulk properties for class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property verbose with class SqoopOptions \u003d\u003e true\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property verbose with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property incremental.last.value with class SqoopOptions \u003d\u003e 2015-01-01\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property incremental.last.value with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property db.connect.string with class SqoopOptions \u003d\u003e jdbc:postgresql://localhost:5432/contoso\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property db.connect.string with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.output.delimiters.escape with class SqoopOptions \u003d\u003e 0\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.output.delimiters.escape with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.output.delimiters.enclose.required with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.output.delimiters.enclose.required with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.input.delimiters.field with class SqoopOptions \u003d\u003e 0\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.input.delimiters.field with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hbase.create.table with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hbase.create.table with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hdfs.append.dir with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hdfs.append.dir with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hive.compute.stats.table with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hive.compute.stats.table with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property db.table with class SqoopOptions \u003d\u003e factsales\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property db.table with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.input.delimiters.escape with class SqoopOptions \u003d\u003e 0\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.input.delimiters.escape with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property import.fetch.size with class SqoopOptions \u003d\u003e null\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property import.fetch.size with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property accumulo.create.table with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property accumulo.create.table with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.input.delimiters.enclose.required with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.input.delimiters.enclose.required with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property db.username with class SqoopOptions \u003d\u003e zeppelin\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property db.username with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property reset.onemapper with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property reset.onemapper with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.output.delimiters.record with class SqoopOptions \u003d\u003e 10\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.output.delimiters.record with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property import.max.inline.lob.size with class SqoopOptions \u003d\u003e 16777216\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property import.max.inline.lob.size with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hbase.bulk.load.enabled with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hbase.bulk.load.enabled with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hcatalog.create.table with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hcatalog.create.table with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property db.clear.staging.table with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property db.clear.staging.table with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property incremental.col with class SqoopOptions \u003d\u003e updatedate\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property incremental.col with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.input.delimiters.record with class SqoopOptions \u003d\u003e 0\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.input.delimiters.record with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property db.password.file with class SqoopOptions \u003d\u003e hdfs://sandbox.hortonworks.com:8020/user/zeppelin/.password\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property db.password.file with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property enable.compression with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property enable.compression with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hive.overwrite.table with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hive.overwrite.table with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hive.import with class SqoopOptions \u003d\u003e true\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hive.import with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.input.delimiters.enclose with class SqoopOptions \u003d\u003e 0\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.input.delimiters.enclose with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property accumulo.batch.size with class SqoopOptions \u003d\u003e 10240000\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property accumulo.batch.size with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hive.drop.delims with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hive.drop.delims with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.output.delimiters.enclose with class SqoopOptions \u003d\u003e 0\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.output.delimiters.enclose with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hdfs.delete-target.dir with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hdfs.delete-target.dir with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.output.dir with class SqoopOptions \u003d\u003e .\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.output.dir with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.auto.compile.dir with class SqoopOptions \u003d\u003e true\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.auto.compile.dir with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property relaxed.isolation with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property relaxed.isolation with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property mapreduce.num.mappers with class SqoopOptions \u003d\u003e 4\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property mapreduce.num.mappers with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property accumulo.max.latency with class SqoopOptions \u003d\u003e 5000\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property accumulo.max.latency with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property import.direct.split.size with class SqoopOptions \u003d\u003e 0\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property import.direct.split.size with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.output.delimiters.field with class SqoopOptions \u003d\u003e 1\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.output.delimiters.field with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property export.new.update with class SqoopOptions \u003d\u003e UpdateOnly\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property export.new.update with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property incremental.mode with class SqoopOptions \u003d\u003e DateLastModified\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property incremental.mode with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hdfs.file.format with class SqoopOptions \u003d\u003e TextFile\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hdfs.file.format with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property codegen.compile.dir with class SqoopOptions \u003d\u003e /tmp/sqoop-zeppelin/compile/eae9c49ca45201cdaa1cc635ff267230\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property codegen.compile.dir with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property direct.import with class SqoopOptions \u003d\u003e true\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property direct.import with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property hive.fail.table.exists with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property hive.fail.table.exists with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property db.batch with class SqoopOptions \u003d\u003e false\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property db.batch with class SqoopOptions\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Saving sqoop.job.storage.implementations \u003d\u003e com.cloudera.sqoop.metastore.hsqldb.HsqldbJobStorage,com.cloudera.sqoop.metastore.hsqldb.AutoHsqldbStorage / null\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property sqoop.job.storage.implementations with class config \u003d\u003e com.cloudera.sqoop.metastore.hsqldb.HsqldbJobStorage,com.cloudera.sqoop.metastore.hsqldb.AutoHsqldbStorage\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property sqoop.job.storage.implementations with class config\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Saving rpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB \u003d\u003e org.apache.hadoop.ipc.ProtobufRpcEngine / null\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property rpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB with class config \u003d\u003e org.apache.hadoop.ipc.ProtobufRpcEngine\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property rpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB with class config\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Saving mapreduce.client.genericoptionsparser.used \u003d\u003e true / null\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Setting property mapreduce.client.genericoptionsparser.used with class config \u003d\u003e true\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Job: factsales; Getting property mapreduce.client.genericoptionsparser.used with class config\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage:  \u003d\u003e (no result)\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Flushing current transaction\n16/01/13 14:56:04 DEBUG hsqldb.HsqldbJobStorage: Closing connection\n"
      },
      "dateCreated": "Jan 13, 2016 2:54:24 PM",
      "dateStarted": "Jan 13, 2016 2:56:01 PM",
      "dateFinished": "Jan 13, 2016 2:56:04 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Update 2 records of FactSales table (in Postgres)",
      "text": "%sh\nexport PGPASSWORD\u003dzeppelin\npsql -U zeppelin -d contoso -h localhost -c \"update factsales set updatedate \u003d \u00272016-01-01 00:00:00\u0027 where saleskey in (1,2);\"",
      "dateUpdated": "Jan 13, 2016 3:02:20 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452696961141_1657497685",
      "id": "20160113-145601_209551253",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "UPDATE 2\n"
      },
      "dateCreated": "Jan 13, 2016 2:56:01 PM",
      "dateStarted": "Jan 13, 2016 2:57:21 PM",
      "dateFinished": "Jan 13, 2016 2:57:22 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Empty the staging table in hive",
      "text": "%hive\ntruncate table factsales",
      "dateUpdated": "Jan 13, 2016 3:07:55 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452697017347_819391987",
      "id": "20160113-145657_1022207805",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 2:56:57 PM",
      "dateStarted": "Jan 13, 2016 3:01:11 PM",
      "dateFinished": "Jan 13, 2016 3:01:12 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Execute incremental sqoop job",
      "text": "%sh\n\n\n\n#Copies Records Modified In PostGres To Hive\n\nsqoop job -exec factsales",
      "dateUpdated": "Jan 13, 2016 3:10:57 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true,
        "tableHide": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452697271922_-2049540476",
      "id": "20160113-150111_393582518",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "Warning: /usr/hdp/2.3.2.0-2950/accumulo does not exist! Accumulo imports will fail.\nPlease set $ACCUMULO_HOME to the root of your Accumulo installation.\n16/01/13 15:10:59 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6.2.3.2.0-2950\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/zookeeper/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n16/01/13 15:11:00 DEBUG sqoop.ConnFactory: Loaded manager factory: org.apache.sqoop.manager.oracle.OraOopManagerFactory\n16/01/13 15:11:00 DEBUG sqoop.ConnFactory: Loaded manager factory: com.cloudera.sqoop.manager.DefaultManagerFactory\n16/01/13 15:11:00 DEBUG sqoop.ConnFactory: Trying ManagerFactory: org.apache.sqoop.manager.oracle.OraOopManagerFactory\n16/01/13 15:11:00 DEBUG oracle.OraOopManagerFactory: Data Connector for Oracle and Hadoop can be called by Sqoop!\n16/01/13 15:11:00 DEBUG sqoop.ConnFactory: Trying ManagerFactory: com.cloudera.sqoop.manager.DefaultManagerFactory\n16/01/13 15:11:00 DEBUG manager.DefaultManagerFactory: Trying with scheme: jdbc:postgresql:\n16/01/13 15:11:00 INFO manager.SqlManager: Using default fetchSize of 1000\n16/01/13 15:11:00 DEBUG sqoop.ConnFactory: Instantiated ConnManager org.apache.sqoop.manager.DirectPostgresqlManager@4324438\n16/01/13 15:11:00 INFO tool.CodeGenTool: Beginning code generation\n16/01/13 15:11:00 DEBUG manager.SqlManager: Execute getColumnInfoRawQuery : SELECT t.* FROM \"factsales\" AS t LIMIT 1\n16/01/13 15:11:00 DEBUG manager.SqlManager: No connection paramenters specified. Using regular API for making connection.\n16/01/13 15:11:00 DEBUG manager.SqlManager: Using fetchSize for next query: 1000\n16/01/13 15:11:00 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM \"factsales\" AS t LIMIT 1\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column saleskey of type [4, 10, 0]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column datekey of type [93, 29, 6]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column channelkey of type [4, 10, 0]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column storekey of type [4, 10, 0]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column productkey of type [4, 10, 0]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column promotionkey of type [4, 10, 0]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column currencykey of type [4, 10, 0]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column unitcost of type [8, 17, 17]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column unitprice of type [8, 17, 17]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column salesquantity of type [4, 10, 0]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column returnquantity of type [4, 10, 0]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column returnamount of type [8, 17, 17]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column discountquantity of type [4, 10, 0]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column discountamount of type [8, 17, 17]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column totalcost of type [8, 17, 17]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column salesamount of type [8, 17, 17]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column etlloadid of type [4, 10, 0]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column loaddate of type [93, 29, 6]\n16/01/13 15:11:00 DEBUG manager.SqlManager: Found column updatedate of type [93, 29, 6]\n16/01/13 15:11:00 DEBUG orm.ClassWriter: selected columns:\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   saleskey\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   datekey\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   channelkey\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   storekey\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   productkey\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   promotionkey\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   currencykey\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   unitcost\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   unitprice\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   salesquantity\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   returnquantity\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   returnamount\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   discountquantity\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   discountamount\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   totalcost\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   salesamount\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   etlloadid\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   loaddate\n16/01/13 15:11:00 DEBUG orm.ClassWriter:   updatedate\n16/01/13 15:11:00 DEBUG orm.ClassWriter: Writing source file: /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19/factsales.java\n16/01/13 15:11:00 DEBUG orm.ClassWriter: Table name: factsales\n16/01/13 15:11:00 DEBUG orm.ClassWriter: Columns: saleskey:4, datekey:93, channelkey:4, storekey:4, productkey:4, promotionkey:4, currencykey:4, unitcost:8, unitprice:8, salesquantity:4, returnquantity:4, returnamount:8, discountquantity:4, discountamount:8, totalcost:8, salesamount:8, etlloadid:4, loaddate:93, updatedate:93, \n16/01/13 15:11:00 DEBUG orm.ClassWriter: sourceFilename is factsales.java\n16/01/13 15:11:00 DEBUG orm.CompilationManager: Found existing /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19/\n16/01/13 15:11:00 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/hdp/2.3.2.0-2950/hadoop-mapreduce\n16/01/13 15:11:00 DEBUG orm.CompilationManager: Returning jar file path /usr/hdp/2.3.2.0-2950/hadoop-mapreduce/hadoop-mapreduce-client-core.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/hadoop-mapreduce-client-core-2.7.1.2.3.2.0-2950.jar\n16/01/13 15:11:00 DEBUG orm.CompilationManager: Current sqoop classpath \u003d /usr/hdp/2.3.2.0-2950/hadoop/conf:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/azure-storage-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-api-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-hdfs-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-yarn-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/aws-java-sdk-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-nfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-auth-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-aws-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-azure-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-azure.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-aws.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-auth.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-annotations-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/./:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/okio-1.4.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/okhttp-2.4.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/javassist-3.18.1-GA.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/objenesis-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/fst-2.24.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/zookeeper-3.4.6.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-timeline-plugins.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-registry-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-api-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-client-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-timeline-plugins-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-extras-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-distcp-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-gridmix-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-archives-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-datajoin-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-auth-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-ant-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//joda-time-2.8.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-openstack-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-sls-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-streaming-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-rumen-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/current/hive-client/lib/libthrift-0.9.2.jar::/usr/hdp/2.3.2.0-2950//sqoop/conf:/etc/zookeeper/conf::/usr/hdp/2.3.2.0-2950//sqoop/lib/ant-contrib-1.0b3.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/ant-eclipse-1.0-jvm1.2.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/avro-1.7.5.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/avro-mapred-1.7.5-hadoop2.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/commons-io-1.4.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/commons-jexl-2.1.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/commons-logging-1.1.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/hsqldb-1.8.0.10.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/jackson-annotations-2.3.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/jackson-core-2.3.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/jackson-databind-2.3.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/kite-data-core-1.0.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/kite-data-hive-1.0.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/kite-data-mapreduce-1.0.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/kite-hadoop-compatibility-1.0.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/opencsv-2.3.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-avro-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-column-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-common-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-encoding-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-format-2.0.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-generator-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-hadoop-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-jackson-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/postgresql-9.4.1207.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/snappy-java-1.0.5.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.91.x86_64/lib/tools.jar:/usr/hdp/2.3.2.0-2950/hbase:/usr/hdp/2.3.2.0-2950/hbase/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/asm-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-codec-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-el-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-logging-1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-math-2.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/disruptor-3.3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guava-12.0.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-client-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-client.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-examples-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-examples.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop2-compat-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop2-compat.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop-compat-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop-compat.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-prefix-tree-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-prefix-tree.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-procedure-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-procedure.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-protocol-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-protocol.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-resource-bundle-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-resource-bundle.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-rest-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-rest.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-shell-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-shell.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-thrift-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-thrift.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jamon-runtime-2.3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jcodings-1.0.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jettison-1.3.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-sslengine-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/joni-2.1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jruby-complete-1.6.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsp-2.1-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsr305-1.3.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/libthrift-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/metrics-core-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/netty-3.2.4.Final.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/okhttp-2.4.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/okio-1.4.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/phoenix-server.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-hbase-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/slf4j-api-1.7.7.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/spymemcached-2.11.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xml-apis-1.3.04.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/zookeeper.jar:/usr/hdp/2.3.2.0-2950/hadoop/conf:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/azure-storage-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-api-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-hdfs-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-yarn-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/aws-java-sdk-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-nfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-auth-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-aws-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-azure-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-azure.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-aws.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-auth.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-annotations-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/./:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/okio-1.4.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/okhttp-2.4.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/javassist-3.18.1-GA.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/objenesis-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/fst-2.24.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/zookeeper-3.4.6.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-timeline-plugins.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-registry-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-api-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-client-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-timeline-plugins-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-extras-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-distcp-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-gridmix-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-archives-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-datajoin-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-auth-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-ant-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//joda-time-2.8.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-openstack-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-sls-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-streaming-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-rumen-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//servlet-api-2.5.jar:::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java-5.1.31-bin.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/tez/tez-common-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-examples-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-mapreduce-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-yarn-timeline-history-with-acls-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-runtime-internals-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-api-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-history-parser-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-yarn-timeline-history-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-tests-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-runtime-library-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-dag-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-yarn-server-web-proxy-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.3.2.0-2950/tez/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-aws-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-azure-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-annotations-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-mapreduce-client-core-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-mapreduce-client-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/tez/conf:/usr/hdp/2.3.2.0-2950/hadoop/conf:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-nfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-common.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-auth-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-aws-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-azure-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-common-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-annotations.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-azure.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-aws.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-auth.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-annotations-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-common-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-nfs.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/azure-storage-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-api-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-hdfs-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-yarn-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/aws-java-sdk-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/zookeeper/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/zookeeper/zookeeper.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-artifact-manager-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-http-2.4.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/slf4j-log4j12-1.6.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/xercesMinimal-1.9.6.2.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-profile-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-repository-metadata-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/httpclient-4.2.3.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/ant-launcher-1.8.0.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/jsoup-1.7.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-file-1.0-beta-6.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/commons-io-2.2.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-http-shared4-2.4.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/jline-0.9.94.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/ant-1.8.0.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-provider-api-2.4.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-ant-tasks-2.1.3.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/nekohtml-1.9.6.2.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/commons-codec-1.6.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-error-diagnostics-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/backport-util-concurrent-3.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/log4j-1.2.16.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/plexus-interpolation-1.11.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/plexus-container-default-1.0-alpha-9-stable-1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/plexus-utils-3.0.8.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/httpcore-4.2.3.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-model-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-project-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-http-lightweight-1.0-beta-6.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-http-shared-1.0-beta-6.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-settings-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-artifact-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/commons-logging-1.1.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/netty-3.7.0.Final.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/classworlds-1.1-alpha-2.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-plugin-registry-2.2.1.jar::/usr/hdp/2.3.2.0-2950/atlas/hook/hive/scala-compiler-2.10.4.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/atlas-typesystem-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/scala-reflect-2.10.4.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/scalap-2.10.4.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/atlas-client-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/json4s-core_2.10-3.2.11.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/hive-bridge-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/json4s-native_2.10-3.2.11.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/json4s-ast_2.10-3.2.11.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/scala-library-2.10.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/accumulo-core-1.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/accumulo-fate-1.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/accumulo-start-1.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/accumulo-trace-1.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ant-1.9.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ant-launcher-1.9.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/antlr-2.7.7.jar:/usr/hdp/2.3.2.0-2950/hive/lib/antlr-runtime-3.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/apache-log4j-extras-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hive/lib/asm-commons-3.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/asm-tree-3.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/avro-1.7.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/bonecp-0.8.0.RELEASE.jar:/usr/hdp/2.3.2.0-2950/hive/lib/calcite-avatica-1.2.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/calcite-core-1.2.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/calcite-linq4j-1.2.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-compiler-2.7.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-dbcp-1.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-httpclient-3.0.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-math-2.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-pool-1.5.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-vfs2-2.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/curator-client-2.6.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/curator-framework-2.6.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/datanucleus-api-jdo-3.2.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/datanucleus-core-3.2.10.jar:/usr/hdp/2.3.2.0-2950/hive/lib/datanucleus-rdbms-3.2.9.jar:/usr/hdp/2.3.2.0-2950/hive/lib/derby-10.10.2.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/eigenbase-properties-1.1.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/geronimo-annotation_1.0_spec-1.1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/geronimo-jaspic_1.0_spec-1.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/geronimo-jta_1.1_spec-1.1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/groovy-all-2.1.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/guava-14.0.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hamcrest-core-1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-accumulo-handler-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-accumulo-handler.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-ant-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-ant.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-beeline-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-beeline.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-cli-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-cli.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-contrib-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-contrib.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-exec-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-exec.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-hbase-handler-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-hbase-handler.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-hwi-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-hwi.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-jdbc-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-jdbc-1.2.1.2.3.2.0-2950-standalone.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-jdbc.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-metastore-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-metastore.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-serde-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-serde.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-service-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-service.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-0.20S-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-0.23-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-common-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-common.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-scheduler-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-scheduler.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-testutils-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-testutils.jar:/usr/hdp/2.3.2.0-2950/hive/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hive/lib/httpclient-4.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/httpcore-4.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ivy-2.4.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/janino-2.7.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jcommander-1.32.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jdo-api-3.0.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jetty-all-7.6.0.v20120127.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jetty-all-server-7.6.0.v20120127.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jline-2.12.jar:/usr/hdp/2.3.2.0-2950/hive/lib/joda-time-2.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jpam-1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/json-20090211.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jta-1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hive/lib/libfb303-0.9.2.jar:/usr/hdp/2.3.2.0-2950/hive/lib/libthrift-0.9.2.jar:/usr/hdp/2.3.2.0-2950/hive/lib/log4j-1.2.16.jar:/usr/hdp/2.3.2.0-2950/hive/lib/mail-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/maven-scm-api-1.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/maven-scm-provider-svn-commons-1.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/maven-scm-provider-svnexe-1.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hive/lib/netty-3.7.0.Final.jar:/usr/hdp/2.3.2.0-2950/hive/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/opencsv-2.3.jar:/usr/hdp/2.3.2.0-2950/hive/lib/oro-2.0.8.jar:/usr/hdp/2.3.2.0-2950/hive/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hive/lib/parquet-hadoop-bundle-1.6.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar:/usr/hdp/2.3.2.0-2950/hive/lib/plexus-utils-1.5.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ranger-hive-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/regexp-1.3.jar:/usr/hdp/2.3.2.0-2950/hive/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/snappy-java-1.0.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ST4-4.0.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/stax-api-1.0.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/stringtemplate-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/super-csv-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/tempus-fugit-1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/velocity-1.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/zookeeper-3.4.6.2.3.2.0-2950.jar::/usr/hdp/2.3.2.0-2950/hive-hcatalog/libexec/../share/hcatalog/hive-hcatalog-core-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/conf::/usr/hdp/2.3.2.0-2950/hbase/lib/netty-3.2.4.Final.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-procedure.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-resource-bundle-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop2-compat.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-examples.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop-compat.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-rest.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop2-compat-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jcodings-1.0.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-prefix-tree.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsp-2.1-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-math-2.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/phoenix-server.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-codec-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-hbase-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/asm-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/joni-2.1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-client-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-shell-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsr305-1.3.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/disruptor-3.3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-prefix-tree-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guava-12.0.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/spymemcached-2.11.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-resource-bundle.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-rest-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-client.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-logging-1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-sslengine-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-shell.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-examples-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jruby-complete-1.6.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/zookeeper.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/slf4j-api-1.7.7.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jamon-runtime-2.3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop-compat-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/okio-1.4.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xml-apis-1.3.04.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/metrics-core-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-el-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-protocol.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/okhttp-2.4.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jettison-1.3.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-procedure-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-protocol-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/conf::/usr/hdp/2.3.2.0-2950//sqoop/sqoop-1.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950//sqoop/sqoop-test-1.4.6.2.3.2.0-2950.jar:::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java-5.1.31-bin.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/tez/tez-common-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-examples-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-mapreduce-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-yarn-timeline-history-with-acls-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-runtime-internals-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-api-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-history-parser-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-yarn-timeline-history-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-tests-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-runtime-library-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-dag-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-yarn-server-web-proxy-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.3.2.0-2950/tez/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-aws-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-azure-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-annotations-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-mapreduce-client-core-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-mapreduce-client-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/tez/conf\n16/01/13 15:11:00 DEBUG orm.CompilationManager: Adding source file: /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19/factsales.java\n16/01/13 15:11:00 DEBUG orm.CompilationManager: Invoking javac with args:\n16/01/13 15:11:00 DEBUG orm.CompilationManager:   -sourcepath\n16/01/13 15:11:00 DEBUG orm.CompilationManager:   /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19/\n16/01/13 15:11:00 DEBUG orm.CompilationManager:   -d\n16/01/13 15:11:00 DEBUG orm.CompilationManager:   /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19/\n16/01/13 15:11:00 DEBUG orm.CompilationManager:   -classpath\n16/01/13 15:11:00 DEBUG orm.CompilationManager:   /usr/hdp/2.3.2.0-2950/hadoop/conf:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/azure-storage-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-api-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-hdfs-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-yarn-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/aws-java-sdk-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-nfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-auth-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-aws-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-azure-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-azure.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-aws.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-auth.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-annotations-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/./:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/okio-1.4.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/okhttp-2.4.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/javassist-3.18.1-GA.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/objenesis-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/fst-2.24.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/zookeeper-3.4.6.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-timeline-plugins.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-registry-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-api-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-client-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-timeline-plugins-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-extras-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-distcp-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-gridmix-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-archives-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-datajoin-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-auth-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-ant-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//joda-time-2.8.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-openstack-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-sls-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-streaming-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-rumen-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/current/hive-client/lib/libthrift-0.9.2.jar::/usr/hdp/2.3.2.0-2950//sqoop/conf:/etc/zookeeper/conf::/usr/hdp/2.3.2.0-2950//sqoop/lib/ant-contrib-1.0b3.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/ant-eclipse-1.0-jvm1.2.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/avro-1.7.5.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/avro-mapred-1.7.5-hadoop2.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/commons-io-1.4.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/commons-jexl-2.1.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/commons-logging-1.1.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/hsqldb-1.8.0.10.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/jackson-annotations-2.3.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/jackson-core-2.3.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/jackson-databind-2.3.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/kite-data-core-1.0.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/kite-data-hive-1.0.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/kite-data-mapreduce-1.0.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/kite-hadoop-compatibility-1.0.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/opencsv-2.3.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-avro-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-column-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-common-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-encoding-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-format-2.0.0.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-generator-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-hadoop-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/parquet-jackson-1.4.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/postgresql-9.4.1207.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/snappy-java-1.0.5.jar:/usr/hdp/2.3.2.0-2950//sqoop/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.91.x86_64/lib/tools.jar:/usr/hdp/2.3.2.0-2950/hbase:/usr/hdp/2.3.2.0-2950/hbase/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/asm-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-codec-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-el-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-logging-1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-math-2.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/disruptor-3.3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guava-12.0.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-client-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-client.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-examples-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-examples.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop2-compat-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop2-compat.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop-compat-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop-compat.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-prefix-tree-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-prefix-tree.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-procedure-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-procedure.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-protocol-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-protocol.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-resource-bundle-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-resource-bundle.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-rest-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-rest.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-shell-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-shell.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-thrift-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-thrift.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jamon-runtime-2.3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jcodings-1.0.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jettison-1.3.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-sslengine-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/joni-2.1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jruby-complete-1.6.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsp-2.1-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsr305-1.3.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/libthrift-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/metrics-core-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/netty-3.2.4.Final.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/okhttp-2.4.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/okio-1.4.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/phoenix-server.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-hbase-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/slf4j-api-1.7.7.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/spymemcached-2.11.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xml-apis-1.3.04.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/zookeeper.jar:/usr/hdp/2.3.2.0-2950/hadoop/conf:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/azure-storage-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-api-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-hdfs-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-yarn-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/aws-java-sdk-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-nfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-auth-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-aws-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-azure-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-azure.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-aws.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-auth.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-annotations-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-common-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/./:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/okio-1.4.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/okhttp-2.4.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.3.2.0-2950/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/javassist-3.18.1-GA.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/objenesis-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/fst-2.24.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/zookeeper-3.4.6.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-timeline-plugins.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-registry-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-api-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-client-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-timeline-plugins-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.3.2.0-2950/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-extras-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-distcp-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-gridmix-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-archives-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-datajoin-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-auth-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-ant-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//joda-time-2.8.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-openstack-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-sls-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-streaming-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//hadoop-rumen-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/.//servlet-api-2.5.jar:::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java-5.1.31-bin.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/tez/tez-common-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-examples-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-mapreduce-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-yarn-timeline-history-with-acls-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-runtime-internals-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-api-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-history-parser-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-yarn-timeline-history-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-tests-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-runtime-library-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-dag-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-yarn-server-web-proxy-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.3.2.0-2950/tez/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-aws-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-azure-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-annotations-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-mapreduce-client-core-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-mapreduce-client-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/tez/conf:/usr/hdp/2.3.2.0-2950/hadoop/conf:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-nfs-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-common.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-auth-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-aws-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-azure-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-common-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-annotations.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-azure.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-aws.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-auth.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-annotations-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-common-2.7.1.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hadoop/hadoop-nfs.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/azure-storage-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/asm-3.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/hadoop-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-api-1.7.10.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-hdfs-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger-yarn-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/aws-java-sdk-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/zookeeper/zookeeper-3.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/zookeeper/zookeeper.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-artifact-manager-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-http-2.4.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/slf4j-log4j12-1.6.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/xercesMinimal-1.9.6.2.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-profile-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-repository-metadata-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/httpclient-4.2.3.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/ant-launcher-1.8.0.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/jsoup-1.7.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-file-1.0-beta-6.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/commons-io-2.2.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-http-shared4-2.4.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/jline-0.9.94.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/ant-1.8.0.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-provider-api-2.4.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-ant-tasks-2.1.3.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/nekohtml-1.9.6.2.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/commons-codec-1.6.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-error-diagnostics-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/backport-util-concurrent-3.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/log4j-1.2.16.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/plexus-interpolation-1.11.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/plexus-container-default-1.0-alpha-9-stable-1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/plexus-utils-3.0.8.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/httpcore-4.2.3.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-model-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-project-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-http-lightweight-1.0-beta-6.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/wagon-http-shared-1.0-beta-6.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-settings-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-artifact-2.2.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/commons-logging-1.1.1.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/netty-3.7.0.Final.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/classworlds-1.1-alpha-2.jar:/usr/hdp/2.3.2.0-2950/zookeeper/lib/maven-plugin-registry-2.2.1.jar::/usr/hdp/2.3.2.0-2950/atlas/hook/hive/scala-compiler-2.10.4.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/atlas-typesystem-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/scala-reflect-2.10.4.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/scalap-2.10.4.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/atlas-client-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/json4s-core_2.10-3.2.11.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/hive-bridge-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/json4s-native_2.10-3.2.11.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/json4s-ast_2.10-3.2.11.jar:/usr/hdp/2.3.2.0-2950/atlas/hook/hive/scala-library-2.10.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/accumulo-core-1.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/accumulo-fate-1.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/accumulo-start-1.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/accumulo-trace-1.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ant-1.9.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ant-launcher-1.9.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/antlr-2.7.7.jar:/usr/hdp/2.3.2.0-2950/hive/lib/antlr-runtime-3.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/apache-log4j-extras-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hive/lib/asm-commons-3.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/asm-tree-3.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/avro-1.7.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/bonecp-0.8.0.RELEASE.jar:/usr/hdp/2.3.2.0-2950/hive/lib/calcite-avatica-1.2.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/calcite-core-1.2.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/calcite-linq4j-1.2.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-compiler-2.7.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-dbcp-1.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-httpclient-3.0.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-logging-1.1.3.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-math-2.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-pool-1.5.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/commons-vfs2-2.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/curator-client-2.6.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/curator-framework-2.6.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/datanucleus-api-jdo-3.2.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/datanucleus-core-3.2.10.jar:/usr/hdp/2.3.2.0-2950/hive/lib/datanucleus-rdbms-3.2.9.jar:/usr/hdp/2.3.2.0-2950/hive/lib/derby-10.10.2.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/eigenbase-properties-1.1.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/geronimo-annotation_1.0_spec-1.1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/geronimo-jaspic_1.0_spec-1.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/geronimo-jta_1.1_spec-1.1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/groovy-all-2.1.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/guava-14.0.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hamcrest-core-1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-accumulo-handler-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-accumulo-handler.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-ant-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-ant.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-beeline-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-beeline.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-cli-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-cli.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-contrib-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-contrib.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-exec-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-exec.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-hbase-handler-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-hbase-handler.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-hwi-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-hwi.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-jdbc-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-jdbc-1.2.1.2.3.2.0-2950-standalone.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-jdbc.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-metastore-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-metastore.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-serde-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-serde.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-service-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-service.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-0.20S-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-0.23-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-common-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-common.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-scheduler-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-shims-scheduler.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-testutils-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/hive-testutils.jar:/usr/hdp/2.3.2.0-2950/hive/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hive/lib/httpclient-4.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/httpcore-4.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ivy-2.4.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/janino-2.7.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jcommander-1.32.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jdo-api-3.0.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jetty-all-7.6.0.v20120127.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jetty-all-server-7.6.0.v20120127.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jline-2.12.jar:/usr/hdp/2.3.2.0-2950/hive/lib/joda-time-2.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jpam-1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/json-20090211.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jsr305-3.0.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/jta-1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hive/lib/libfb303-0.9.2.jar:/usr/hdp/2.3.2.0-2950/hive/lib/libthrift-0.9.2.jar:/usr/hdp/2.3.2.0-2950/hive/lib/log4j-1.2.16.jar:/usr/hdp/2.3.2.0-2950/hive/lib/mail-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/maven-scm-api-1.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/maven-scm-provider-svn-commons-1.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/maven-scm-provider-svnexe-1.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hive/lib/netty-3.7.0.Final.jar:/usr/hdp/2.3.2.0-2950/hive/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/opencsv-2.3.jar:/usr/hdp/2.3.2.0-2950/hive/lib/oro-2.0.8.jar:/usr/hdp/2.3.2.0-2950/hive/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hive/lib/parquet-hadoop-bundle-1.6.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar:/usr/hdp/2.3.2.0-2950/hive/lib/plexus-utils-1.5.6.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ranger-hive-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/lib/regexp-1.3.jar:/usr/hdp/2.3.2.0-2950/hive/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/snappy-java-1.0.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/ST4-4.0.4.jar:/usr/hdp/2.3.2.0-2950/hive/lib/stax-api-1.0.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/stringtemplate-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/super-csv-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/tempus-fugit-1.1.jar:/usr/hdp/2.3.2.0-2950/hive/lib/velocity-1.5.jar:/usr/hdp/2.3.2.0-2950/hive/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hive/lib/zookeeper-3.4.6.2.3.2.0-2950.jar::/usr/hdp/2.3.2.0-2950/hive-hcatalog/libexec/../share/hcatalog/hive-hcatalog-core-1.2.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hive/conf::/usr/hdp/2.3.2.0-2950/hbase/lib/netty-3.2.4.Final.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-audit-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-procedure.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xz-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-resource-bundle-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/noggit-0.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop2-compat.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-httpclient-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-examples.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop-compat.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpcore-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-common-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsch-0.1.42.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-rest.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop2-compat-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jcodings-1.0.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-prefix-tree.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/log4j-1.2.17.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jets3t-0.9.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsp-2.1-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-math-2.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/phoenix-server.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/activation-1.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-guice-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-codec-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-client-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guice-servlet-3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpclient-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-hbase-plugin-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/asm-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guice-3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/joni-2.1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-client-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xmlenc-0.52.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-shell-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-core-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsr305-1.3.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/disruptor-3.3.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-digester-1.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-prefix-tree-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/guava-12.0.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/spymemcached-2.11.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-resource-bundle.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-rest-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/paranamer-2.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-client.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-logging-1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-sslengine-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-shell.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/avro-1.7.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-examples-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jruby-complete-1.6.8.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/gson-2.2.4.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger-plugins-cred-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/junit-4.11.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/zookeeper.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/slf4j-api-1.7.7.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jamon-runtime-2.3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-hadoop-compat-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/httpmime-4.2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/okio-1.4.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/xml-apis-1.3.04.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/curator-framework-2.7.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/metrics-core-2.2.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-server-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-el-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-net-3.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ojdbc6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-it-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jersey-server-1.9.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-configuration-1.6.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common-1.1.2.2.3.2.0-2950-tests.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-protocol.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/okhttp-2.4.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/ranger_solrj-0.5.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jettison-1.3.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-procedure-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/javax.inject-1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/commons-compress-1.4.1.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/aopalliance-1.0.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/jackson-core-2.2.3.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-common-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-annotations-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/hbase-protocol-1.1.2.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/2.3.2.0-2950/hbase/conf::/usr/hdp/2.3.2.0-2950//sqoop/sqoop-1.4.6.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950//sqoop/sqoop-test-1.4.6.2.3.2.0-2950.jar:::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java-5.1.31-bin.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/2.3.2.0-2950/tez/tez-common-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-examples-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-mapreduce-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-yarn-timeline-history-with-acls-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-runtime-internals-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-api-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-history-parser-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-yarn-timeline-history-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-tests-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-runtime-library-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/tez-dag-0.7.0.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-io-2.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-yarn-server-web-proxy-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.3.2.0-2950/tez/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.3.2.0-2950/tez/lib/guava-11.0.2.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jersey-client-1.9.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-aws-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jersey-json-1.9.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-azure-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-annotations-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.3.2.0-2950/tez/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.3.2.0-2950/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-mapreduce-client-core-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/hadoop-mapreduce-client-common-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/tez/lib/servlet-api-2.5.jar:/usr/hdp/2.3.2.0-2950/tez/conf:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/hadoop-mapreduce-client-core.jar:/usr/hdp/2.3.2.0-2950/hadoop-mapreduce/hadoop-mapreduce-client-core-2.7.1.2.3.2.0-2950.jar:/usr/hdp/2.3.2.0-2950/sqoop/sqoop-1.4.6.2.3.2.0-2950.jar\nNote: /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19/factsales.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n16/01/13 15:11:02 DEBUG orm.CompilationManager: Could not rename /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19/factsales.java to /home/zeppelin/./factsales.java\n16/01/13 15:11:02 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19/factsales.jar\n16/01/13 15:11:02 DEBUG orm.CompilationManager: Scanning for .class files in directory: /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19\n16/01/13 15:11:02 DEBUG orm.CompilationManager: Got classfile: /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19/factsales.class -\u003e factsales.class\n16/01/13 15:11:02 DEBUG orm.CompilationManager: Finished writing jar file /tmp/sqoop-zeppelin/compile/c6308e4b6a2197ab4801fbec5340ef19/factsales.jar\n16/01/13 15:11:02 DEBUG tool.ImportTool: Using temporary folder: b3e835f377a643c7a36af29e664efd82_factsales\n16/01/13 15:11:02 DEBUG manager.SqlManager: Execute getColumnInfoRawQuery : SELECT t.* FROM \"factsales\" AS t LIMIT 1\n16/01/13 15:11:02 DEBUG manager.SqlManager: Using fetchSize for next query: 1000\n16/01/13 15:11:02 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM \"factsales\" AS t LIMIT 1\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column saleskey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column datekey of type [93, 29, 6]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column channelkey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column storekey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column productkey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column promotionkey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column currencykey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column unitcost of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column unitprice of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column salesquantity of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column returnquantity of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column returnamount of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column discountquantity of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column discountamount of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column totalcost of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column salesamount of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column etlloadid of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column loaddate of type [93, 29, 6]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column updatedate of type [93, 29, 6]\n16/01/13 15:11:02 INFO tool.ImportTool: Incremental import based on column \"updatedate\"\n16/01/13 15:11:02 INFO tool.ImportTool: Lower bound value: \u00272016-01-13 15:02:33.061713\u0027\n16/01/13 15:11:02 INFO tool.ImportTool: Upper bound value: \u00272016-01-13 15:11:02.281533\u0027\n16/01/13 15:11:02 INFO manager.DirectPostgresqlManager: Beginning psql fast path import\n16/01/13 15:11:02 DEBUG manager.SqlManager: Using fetchSize for next query: 1000\n16/01/13 15:11:02 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM \"factsales\" AS t LIMIT 1\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column saleskey of type int4\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column datekey of type timestamp\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column channelkey of type int4\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column storekey of type int4\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column productkey of type int4\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column promotionkey of type int4\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column currencykey of type int4\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column unitcost of type float8\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column unitprice of type float8\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column salesquantity of type int4\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column returnquantity of type int4\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column returnamount of type float8\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column discountquantity of type int4\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column discountamount of type float8\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column totalcost of type float8\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column salesamount of type float8\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column etlloadid of type int4\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column loaddate of type timestamp\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column updatedate of type timestamp\n16/01/13 15:11:02 INFO manager.DirectPostgresqlManager: Copy command is COPY (SELECT \"saleskey\", \"datekey\", \"channelkey\", \"storekey\", \"productkey\", \"promotionkey\", \"currencykey\", \"unitcost\", \"unitprice\", \"salesquantity\", \"returnquantity\", \"returnamount\", \"discountquantity\", \"discountamount\", \"totalcost\", \"salesamount\", \"etlloadid\", \"loaddate\", \"updatedate\" FROM \"factsales\" WHERE \"updatedate\" \u003e\u003d \u00272016-01-13 15:02:33.061713\u0027 AND \"updatedate\" \u003c \u00272016-01-13 15:11:02.281533\u0027) TO STDOUT WITH DELIMITER E\u0027\\1\u0027 CSV ;\n16/01/13 15:11:02 INFO manager.DirectPostgresqlManager: Performing import of table factsales from database contoso\n16/01/13 15:11:02 DEBUG util.PostgreSQLUtils: Writing password to tempfile: /tmp/pgpass3817688580549556828.pgpass\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager: Starting psql with arguments:\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   psql\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   --tuples-only\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   --quiet\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   --username\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   zeppelin\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   --host\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   localhost\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   --port\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   5432\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   contoso\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   -f\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager:   /tmp/tmp-6453408532971595678.sql\n16/01/13 15:11:02 DEBUG util.DirectImportUtils: Writing to filesystem: hdfs://sandbox.hortonworks.com:8020\n16/01/13 15:11:02 DEBUG util.DirectImportUtils: Creating destination directory _sqoop/b3e835f377a643c7a36af29e664efd82_factsales\n16/01/13 15:11:02 DEBUG io.SplittingOutputStream: Opening next output file: _sqoop/b3e835f377a643c7a36af29e664efd82_factsales/part-m-00000\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager: Starting stream sink\n16/01/13 15:11:02 DEBUG manager.DirectPostgresqlManager: Waiting for process completion\n16/01/13 15:11:02 INFO manager.DirectPostgresqlManager: Transfer loop complete.\n16/01/13 15:11:02 INFO manager.DirectPostgresqlManager: Transferred 0 bytes in 0.5068 seconds (0 bytes/sec)\n16/01/13 15:11:02 DEBUG hive.HiveImport: Hive.inputTable: factsales\n16/01/13 15:11:02 DEBUG hive.HiveImport: Hive.outputTable: factsales\n16/01/13 15:11:02 DEBUG manager.SqlManager: Execute getColumnInfoRawQuery : SELECT t.* FROM \"factsales\" AS t LIMIT 1\n16/01/13 15:11:02 DEBUG manager.SqlManager: No connection paramenters specified. Using regular API for making connection.\n16/01/13 15:11:02 DEBUG manager.SqlManager: Using fetchSize for next query: 1000\n16/01/13 15:11:02 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM \"factsales\" AS t LIMIT 1\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column saleskey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column datekey of type [93, 29, 6]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column channelkey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column storekey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column productkey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column promotionkey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column currencykey of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column unitcost of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column unitprice of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column salesquantity of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column returnquantity of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column returnamount of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column discountquantity of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column discountamount of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column totalcost of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column salesamount of type [8, 17, 17]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column etlloadid of type [4, 10, 0]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column loaddate of type [93, 29, 6]\n16/01/13 15:11:02 DEBUG manager.SqlManager: Found column updatedate of type [93, 29, 6]\n16/01/13 15:11:02 WARN hive.TableDefWriter: Column datekey had to be cast to a less precise type in Hive\n16/01/13 15:11:02 WARN hive.TableDefWriter: Column loaddate had to be cast to a less precise type in Hive\n16/01/13 15:11:02 WARN hive.TableDefWriter: Column updatedate had to be cast to a less precise type in Hive\n16/01/13 15:11:02 DEBUG hive.TableDefWriter: Create statement: CREATE TABLE IF NOT EXISTS `factsales` ( `saleskey` INT, `datekey` STRING, `channelkey` INT, `storekey` INT, `productkey` INT, `promotionkey` INT, `currencykey` INT, `unitcost` DOUBLE, `unitprice` DOUBLE, `salesquantity` INT, `returnquantity` INT, `returnamount` DOUBLE, `discountquantity` INT, `discountamount` DOUBLE, `totalcost` DOUBLE, `salesamount` DOUBLE, `etlloadid` INT, `loaddate` STRING, `updatedate` STRING) COMMENT \u0027Imported by sqoop on 2016/01/13 15:11:02\u0027 ROW FORMAT DELIMITED FIELDS TERMINATED BY \u0027\\001\u0027 LINES TERMINATED BY \u0027\\012\u0027 STORED AS TEXTFILE\n16/01/13 15:11:02 DEBUG hive.TableDefWriter: Load statement: LOAD DATA INPATH \u0027hdfs://sandbox.hortonworks.com:8020/user/zeppelin/factsales\u0027 INTO TABLE `factsales`\n16/01/13 15:11:02 INFO hive.HiveImport: Loading uploaded data into Hive\n16/01/13 15:11:02 DEBUG hive.HiveImport: Using in-process Hive instance.\n16/01/13 15:11:02 DEBUG util.SubprocessSecurityManager: Installing subprocess security manager\n\nLogging initialized using configuration in jar:file:/usr/hdp/2.3.2.0-2950/hive/lib/hive-common-1.2.1.2.3.2.0-2950.jar!/hive-log4j.properties\nOK\nTime taken: 1.476 seconds\nLoading data to table default.factsales\nchgrp: changing ownership of \u0027hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/factsales/part-m-00000_copy_1\u0027: User does not belong to hdfs\nTable default.factsales stats: [numFiles\u003d2, numRows\u003d0, totalSize\u003d230, rawDataSize\u003d0]\nOK\nTime taken: 6.132 seconds\n"
      },
      "dateCreated": "Jan 13, 2016 3:01:11 PM",
      "dateStarted": "Jan 13, 2016 3:10:57 PM",
      "dateFinished": "Jan 13, 2016 3:11:17 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Confirm only 2 records picked up",
      "text": "%hive\nSELECT * FROM factsales limit 2",
      "dateUpdated": "Jan 13, 2016 3:09:08 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "factsales.saleskey",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "factsales.datekey",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "factsales.saleskey",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "factsales.datekey",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452697348070_1752886932",
      "id": "20160113-150228_694373324",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "factsales.saleskey\tfactsales.datekey\tfactsales.channelkey\tfactsales.storekey\tfactsales.productkey\tfactsales.promotionkey\tfactsales.currencykey\tfactsales.unitcost\tfactsales.unitprice\tfactsales.salesquantity\tfactsales.returnquantity\tfactsales.returnamount\tfactsales.discountquantity\tfactsales.discountamount\tfactsales.totalcost\tfactsales.salesamount\tfactsales.etlloadid\tfactsales.loaddate\tfactsales.updatedate\n1\t2007-01-02 00:00:00\t1\t209\t956\t10\t1\t91.05\t198.0\t8\t0\t0.0\t1\t39.6\t728.4\t1544.4\t1\t2010-01-01 00:00:00\t2016-01-01 00:00:00\t\n2\t2007-02-12 00:00:00\t4\t308\t766\t2\t1\t10.15\t19.9\t4\t0\t0.0\t1\t0.995\t40.6\t78.605\t1\t2010-01-01 00:00:00\t2016-01-01 00:00:00\t\n"
      },
      "dateCreated": "Jan 13, 2016 3:02:28 PM",
      "dateStarted": "Jan 13, 2016 3:07:33 PM",
      "dateFinished": "Jan 13, 2016 3:07:35 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nIn Hive, move data from staging table to final table (one at a time, using Hive view)\n  - first **remove the common records** from final table that are also found in staging table\n  - **copy data** from staging table to final table\n  - **truncate staging table**",
      "dateUpdated": "Jan 13, 2016 3:14:14 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452697653323_2017824037",
      "id": "20160113-150733_1778308435",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eIn Hive, move data from staging table to final table (one at a time, using Hive view)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efirst \u003cstrong\u003eremove the common records\u003c/strong\u003e from final table that are also found in staging table\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ecopy data\u003c/strong\u003e from staging table to final table\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003etruncate staging table\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 3:07:33 PM",
      "dateStarted": "Jan 13, 2016 3:14:12 PM",
      "dateFinished": "Jan 13, 2016 3:14:12 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\ndelete from factsales_final where saleskey in (select saleskey from factsales)",
      "dateUpdated": "Jan 13, 2016 3:12:00 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452697890835_1951768176",
      "id": "20160113-151130_1609744197",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 3:11:30 PM",
      "dateStarted": "Jan 13, 2016 3:12:00 PM",
      "dateFinished": "Jan 13, 2016 3:12:33 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\ninsert into factsales_final select * from factsales",
      "dateUpdated": "Jan 13, 2016 3:12:51 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452697920377_-595792210",
      "id": "20160113-151200_1664420707",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 3:12:00 PM",
      "dateStarted": "Jan 13, 2016 3:12:51 PM",
      "dateFinished": "Jan 13, 2016 3:13:00 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\ntruncate table factsales",
      "dateUpdated": "Jan 13, 2016 3:13:18 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452697971040_-1344837021",
      "id": "20160113-151251_1614595733",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 3:12:51 PM",
      "dateStarted": "Jan 13, 2016 3:13:18 PM",
      "dateFinished": "Jan 13, 2016 3:13:18 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCheck the updated date on the records in final table in Hive to confirm the *updatedate* column was updated to *2016-01-01*",
      "dateUpdated": "Jan 13, 2016 3:17:33 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452697998079_1662557952",
      "id": "20160113-151318_1279235236",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eCheck the updated date on the records in final table in Hive to confirm the \u003cem\u003eupdatedate\u003c/em\u003e column was updated to \u003cem\u003e2016-01-01\u003c/em\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 3:13:18 PM",
      "dateStarted": "Jan 13, 2016 3:17:31 PM",
      "dateFinished": "Jan 13, 2016 3:17:31 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nselect * from  factsales_final where saleskey in (1,2)",
      "dateUpdated": "Jan 13, 2016 3:16:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452698183248_1147103339",
      "id": "20160113-151623_1092942102",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "factsales_final.saleskey\tfactsales_final.datekey\tfactsales_final.channelkey\tfactsales_final.storekey\tfactsales_final.productkey\tfactsales_final.promotionkey\tfactsales_final.currencykey\tfactsales_final.unitcost\tfactsales_final.unitprice\tfactsales_final.salesquantity\tfactsales_final.returnquantity\tfactsales_final.returnamount\tfactsales_final.discountquantity\tfactsales_final.discountamount\tfactsales_final.totalcost\tfactsales_final.salesamount\tfactsales_final.etlloadid\tfactsales_final.loaddate\tfactsales_final.updatedate\n1\t2007-01-02 00:00:00.0\t1\t209\t956\t10\t1\t91.05000305175781\t198.0\t8\t0\t0.0\t1\t39.599998474121094\t728.4000244140625\t1544.4000244140625\t1\t2010-01-01 00:00:00.0\t2016-01-01 00:00:00.0\t\n2\t2007-02-12 00:00:00.0\t4\t308\t766\t2\t1\t10.149999618530273\t19.899999618530273\t4\t0\t0.0\t1\t0.9950000047683716\t40.599998474121094\t78.6050033569336\t1\t2010-01-01 00:00:00.0\t2016-01-01 00:00:00.0\t\n"
      },
      "dateCreated": "Jan 13, 2016 3:16:23 PM",
      "dateStarted": "Jan 13, 2016 3:16:29 PM",
      "dateFinished": "Jan 13, 2016 3:16:32 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Part 1 complete\n\nAt this point we have shown how you can bulk import data from EDW/RDBMS into Hive and then incrementally keep the Hive tables periodically updated",
      "dateUpdated": "Jan 13, 2016 3:34:45 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452698189856_-1407629358",
      "id": "20160113-151629_1265697908",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4\u003ePart 1 complete\u003c/h4\u003e\n\u003cp\u003eAt this point we have shown how you can bulk import data from EDW/RDBMS into Hive and then incrementally keep the Hive tables periodically updated\u003c/p\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 3:16:29 PM",
      "dateStarted": "Jan 13, 2016 3:34:43 PM",
      "dateFinished": "Jan 13, 2016 3:34:43 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Part 2 \u0026 Part 3: Ingest product-related tweets and weblogs into HDFS via Nifi\n\na) Follow steps below to install Nifi via Ambari, monitor certain tweets and push to HDFS, Hive and Solr:\n\n- Download Nifi Ambari service folder\n```\nVERSION\u003d`hdp-select status hadoop-client | sed \u0027s/hadoop-client - \\([0-9]\\.[0-9]\\).*/\\1/\u0027`\nsudo git clone https://github.com/abajwa-hw/ambari-nifi-service.git   /var/lib/ambari-server/resources/stacks/HDP/$VERSION/services/NIFI   \nsudo service ambari restart\n```\n- To install Nifi, start the \u0027Install Wizard\u0027: Open Ambari (http://sandbox.hortonworks.com:8080) then:\nOn bottom left -\u003e Actions -\u003e Add service -\u003e check NiFi server -\u003e Next -\u003e Next -\u003e Change any config you like (e.g. install dir, port, setup_prebuilt or values in nifi.properties) -\u003e Next -\u003e Deploy. This will kick off the install which will run for 5-10min.\n\n- Now open Nifi webui (http://sandbox.hortonworks.com:9090)\n- Download prebuilt Single_view_demo.xml template to your laptop from [here](https://github.com/abajwa-hw/ambari-nifi-service/raw/master/demofiles/Single_view_demo.xml)\n- Import the Single_view_demo.xml template info Nifi\n- Fill out env specific configs e.g. your Twitter credentials (see note below)\n- Do not start the flows yet\n\n\nb) More details on how to install Nifi on sandbox and import a template flow to ingest tweets available at [https://community.hortonworks.com/articles/1282/sample-hdfnifi-flow-to-push-tweets-into-solrbanana.html](https://community.hortonworks.com/articles/1282/sample-hdfnifi-flow-to-push-tweets-into-solrbanana.html)\n\nc) Note that to monitor tweets, Twitter requires you to have an account and obtain developer keys by registering an \"app\". Follow steps below to do this:\n- Create a Twitter account and app and get your consumer key/token and access keys/tokens:\n  - Open https://apps.twitter.com \n  - sign in\n  - create new app\n  - fill anything\n  - create access tokens\n",
      "dateUpdated": "Jan 13, 2016 8:07:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452698326170_-1702767869",
      "id": "20160113-151846_689314597",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4\u003ePart 2 \u0026amp; Part 3: Ingest product-related tweets and weblogs into HDFS via Nifi\u003c/h4\u003e\n\u003cp\u003ea) Follow steps below to install Nifi via Ambari, monitor certain tweets and push to HDFS, Hive and Solr:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eDownload Nifi Ambari service folder\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eVERSION\u003d`hdp-select status hadoop-client | sed \u0027s/hadoop-client - \\([0-9]\\.[0-9]\\).*/\\1/\u0027`\nsudo git clone https://github.com/abajwa-hw/ambari-nifi-service.git   /var/lib/ambari-server/resources/stacks/HDP/$VERSION/services/NIFI   \nsudo service ambari restart\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eTo install Nifi, start the \u0027Install Wizard\u0027: Open Ambari (http://sandbox.hortonworks.com:8080) then:\n\u003cbr  /\u003eOn bottom left -\u003e Actions -\u003e Add service -\u003e check NiFi server -\u003e Next -\u003e Next -\u003e Change any config you like (e.g. install dir, port, setup_prebuilt or values in nifi.properties) -\u003e Next -\u003e Deploy. This will kick off the install which will run for 5-10min.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eNow open Nifi webui (http://sandbox.hortonworks.com:9090)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eDownload prebuilt Single_view_demo.xml template to your laptop from \u003ca href\u003d\"https://github.com/abajwa-hw/ambari-nifi-service/raw/master/demofiles/Single_view_demo.xml\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eImport the Single_view_demo.xml template info Nifi\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eFill out env specific configs e.g. your Twitter credentials (see note below)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eDo not start the flows yet\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eb) More details on how to install Nifi on sandbox and import a template flow to ingest tweets available at \u003ca href\u003d\"https://community.hortonworks.com/articles/1282/sample-hdfnifi-flow-to-push-tweets-into-solrbanana.html\"\u003ehttps://community.hortonworks.com/articles/1282/sample-hdfnifi-flow-to-push-tweets-into-solrbanana.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ec) Note that to monitor tweets, Twitter requires you to have an account and obtain developer keys by registering an \u0026ldquo;app\u0026rdquo;. Follow steps below to do this:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreate a Twitter account and app and get your consumer key/token and access keys/tokens:\u003c/li\u003e\n\u003cli\u003eOpen https://apps.twitter.com\u003c/li\u003e\n\u003cli\u003esign in\u003c/li\u003e\n\u003cli\u003ecreate new app\u003c/li\u003e\n\u003cli\u003efill anything\u003c/li\u003e\n\u003cli\u003ecreate access tokens\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 3:18:46 PM",
      "dateStarted": "Jan 13, 2016 8:07:36 PM",
      "dateFinished": "Jan 13, 2016 8:07:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Simulate web browsing log for 10 users",
      "text": "%sh\n/home/zeppelin/single-view-demo/createlog-psql.sh /tmp/data/DimCustomer.csv 10 \u003e\u003e /tmp/webtraffic.log",
      "dateUpdated": "Jan 13, 2016 11:40:48 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452714134778_453431803",
      "id": "20160113-194214_575626716",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Jan 13, 2016 7:42:14 PM",
      "dateStarted": "Jan 13, 2016 11:40:48 PM",
      "dateFinished": "Jan 13, 2016 11:43:00 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nNow start the flows in Nifi using the play button to:\n  - ingest the tweets under /tmp/weblog_staging in HDFS\n  - ingest the weblogs under /tmp/tweets_staging in HDFS",
      "dateUpdated": "Jan 13, 2016 8:16:25 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452714525669_1209213271",
      "id": "20160113-194845_498349085",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eNow start the flows in Nifi using the play button to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eingest the tweets under /tmp/weblog_staging in HDFS\u003c/li\u003e\n\u003cli\u003eingest the weblogs under /tmp/tweets_staging in HDFS\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 7:48:45 PM",
      "dateStarted": "Jan 13, 2016 8:16:21 PM",
      "dateFinished": "Jan 13, 2016 8:16:22 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nOnce started, lets create hive tables for tweets and weblog",
      "dateUpdated": "Jan 13, 2016 8:17:27 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452716208916_-1327044377",
      "id": "20160113-201648_2039794982",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eOnce started, lets create hive tables for tweets and weblog\u003c/p\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 8:16:48 PM",
      "dateStarted": "Jan 13, 2016 8:17:23 PM",
      "dateFinished": "Jan 13, 2016 8:17:24 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\nsudo -u hdfs hadoop fs -chmod -R 777 /tmp/tweets_staging\nsudo -u hdfs hadoop fs -chmod -R 777 /tmp/weblog_staging",
      "dateUpdated": "Jan 13, 2016 10:39:06 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452713882797_-396249179",
      "id": "20160113-193802_1253775053",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "Process exited with an error: 1 (Exit value: 1)"
      },
      "dateCreated": "Jan 13, 2016 7:38:02 PM",
      "dateStarted": "Jan 13, 2016 10:39:06 PM",
      "dateFinished": "Jan 13, 2016 10:39:16 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\ncreate table if not exists tweets(\n  tweet_id bigint, \n  created_unixtime bigint, \n  created_time string, \n  displayname string, \n  msg string,\n  fulltext string\n)\nrow format delimited fields terminated by \"|\"\nlocation \"/tmp/tweets_staging\"",
      "dateUpdated": "Jan 13, 2016 9:10:23 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452699657353_-1066675078",
      "id": "20160113-154057_1955065161",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 3:40:57 PM",
      "dateStarted": "Jan 13, 2016 9:10:23 PM",
      "dateFinished": "Jan 13, 2016 9:10:25 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nselect * from tweets limit 5",
      "dateUpdated": "Jan 13, 2016 9:10:32 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452713839889_1762530927",
      "id": "20160113-193719_921494912",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "tweets.tweet_id\ttweets.created_unixtime\ttweets.created_time\ttweets.displayname\ttweets.msg\ttweets.fulltext\n687356948493238272\t1452713641652\tWed Jan 13 19:34:01 +0000 2016\tdanpobeda\tRT @nestmoscow: Фото животных, спящих в самых неожиданных местах https://t.co/WFDmTgzIkM  #животные #сон #мимими #мимишность #фото https://…\t{\"created_at\":\"Wed Jan 13 19:34:01 +0000 2016\",\"id\":687356948493238272,\"id_str\":\"687356948493238272\",\"text\":\"RT @nestmoscow: \\u0424\\u043e\\u0442\\u043e \\u0436\\u0438\\u0432\\u043e\\u0442\\u043d\\u044b\\u0445, \\u0441\\u043f\\u044f\\u0449\\u0438\\u0445 \\u0432 \\u0441\\u0430\\u043c\\u044b\\u0445 \\u043d\\u0435\\u043e\\u0436\\u0438\\u0434\\u0430\\u043d\\u043d\\u044b\\u0445 \\u043c\\u0435\\u0441\\u0442\\u0430\\u0445 https:\\/\\/t.co\\/WFDmTgzIkM  #\\u0436\\u0438\\u0432\\u043e\\u0442\\u043d\\u044b\\u0435 #\\u0441\\u043e\\u043d #\\u043c\\u0438\\u043c\\u0438\\u043c\\u0438 #\\u043c\\u0438\\u043c\\u0438\\u0448\\u043d\\u043e\\u0441\\u0442\\u044c #\\u0444\\u043e\\u0442\\u043e https:\\/\\/\\u2026\",\"source\":\"\\u003ca href\u003d\\\"http:\\/\\/twitter.com\\\" rel\u003d\\\"nofollow\\\"\\u003eTwitter Web Client\\u003c\\/a\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":1643129834,\"id_str\":\"1643129834\",\"name\":\"\\u0438\\u0432\\u0430\\u043d \\u043f\\u0435\\u0442\\u0440\\u043e\\u0432\\u0438\\u0447\",\"screen_name\":\"danpobeda\",\"location\":\"\\u041a\\u0430\\u043b\\u0438\\u043d\\u0438\\u043d\\u0433\\u0440\\u0430\\u0434\",\"url\":\"http:\\/\\/nest.moscow\\/\",\"description\":\"\\u0441\\u0442\\u0443\\u0434\\u0435\\u043d\\u0442\",\"protected\":false,\"verified\":false,\"followers_count\":4,\"friends_count\":34,\"listed_count\":2,\"favourites_count\":70,\"statuses_count\":305,\"created_at\":\"Sat Aug 03 16:02:24 +0000 2013\",\"utc_offset\":null,\"time_zone\":null,\"geo_enabled\":false,\"lang\":\"ru\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"000000\",\"profile_background_image_url\":\"http:\\/\\/abs.twimg.com\\/images\\/themes\\/theme1\\/bg.png\",\"profile_background_image_url_https\":\"https:\\/\\/abs.twimg.com\\/images\\/themes\\/theme1\\/bg.png\",\"profile_background_tile\":false,\"profile_link_color\":\"9266CC\",\"profile_sidebar_border_color\":\"000000\",\"profile_sidebar_fill_color\":\"000000\",\"profile_text_color\":\"000000\",\"profile_use_background_image\":false,\"profile_image_url\":\"http:\\/\\/pbs.twimg.com\\/profile_images\\/534381549865541633\\/lvnV3hyX_normal.jpeg\",\"profile_image_url_https\":\"https:\\/\\/pbs.twimg.com\\/profile_images\\/534381549865541633\\/lvnV3hyX_normal.jpeg\",\"profile_banner_url\":\"https:\\/\\/pbs.twimg.com\\/profile_banners\\/1643129834\\/1416241516\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"retweeted_status\":{\"created_at\":\"Wed Jan 13 19:30:09 +0000 2016\",\"id\":687355975200845824,\"id_str\":\"687355975200845824\",\"text\":\"\\u0424\\u043e\\u0442\\u043e \\u0436\\u0438\\u0432\\u043e\\u0442\\u043d\\u044b\\u0445, \\u0441\\u043f\\u044f\\u0449\\u0438\\u0445 \\u0432 \\u0441\\u0430\\u043c\\u044b\\u0445 \\u043d\\u0435\\u043e\\u0436\\u0438\\u0434\\u0430\\u043d\\u043d\\u044b\\u0445 \\u043c\\u0435\\u0441\\u0442\\u0430\\u0445 https:\\/\\/t.co\\/WFDmTgzIkM  #\\u0436\\u0438\\u0432\\u043e\\u0442\\u043d\\u044b\\u0435 #\\u0441\\u043e\\u043d #\\u043c\\u0438\\u043c\\u0438\\u043c\\u0438 #\\u043c\\u0438\\u043c\\u0438\\u0448\\u043d\\u043e\\u0441\\u0442\\u044c #\\u0444\\u043e\\u0442\\u043e https:\\/\\/t.co\\/oZOBaUhCaw\",\"source\":\"\\u003ca href\u003d\\\"http:\\/\\/twitter.com\\\" rel\u003d\\\"nofollow\\\"\\u003eTwitter Web Client\\u003c\\/a\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":3004102805,\"id_str\":\"3004102805\",\"name\":\"\\u0413\\u043d\\u0435\\u0437\\u0434\\u044b\\u0448\\u043a\\u043e\",\"screen_name\":\"nestmoscow\",\"location\":null,\"url\":\"http:\\/\\/nest.moscow\\/\",\"description\":\"\\u0412\\u0441\\u0435 \\u043e \\u0434\\u043e\\u043c\\u0435 \\u0438 \\u0441\\u0435\\u043c\\u044c\\u0435)\",\"protected\":false,\"verified\":false,\"followers_count\":385,\"friends_count\":18,\"listed_count\":2,\"favourites_count\":17,\"statuses_count\":386,\"created_at\":\"Thu Jan 29 12:52:01 +0000 2015\",\"utc_offset\":null,\"time_zone\":null,\"geo_enabled\":false,\"lang\":\"ru\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"B2DFDA\",\"profile_background_image_url\":\"http:\\/\\/abs.twimg.com\\/images\\/themes\\/theme13\\/bg.gif\",\"profile_background_image_url_https\":\"https:\\/\\/abs.twimg.com\\/images\\/themes\\/theme13\\/bg.gif\",\"profile_background_tile\":false,\"profile_link_color\":\"93A644\",\"profile_sidebar_border_color\":\"EEEEEE\",\"profile_sidebar_fill_color\":\"FFFFFF\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\/\\/pbs.twimg.com\\/profile_images\\/578663423174561792\\/heRHHcCL_normal.jpeg\",\"profile_image_url_https\":\"https:\\/\\/pbs.twimg.com\\/profile_images\\/578663423174561792\\/heRHHcCL_normal.jpeg\",\"profile_banner_url\":\"https:\\/\\/pbs.twimg.com\\/profile_banners\\/3004102805\\/1426528099\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":2,\"favorite_count\":2,\"entities\":{\"hashtags\":[{\"text\":\"\\u0436\\u0438\\u0432\\u043e\\u0442\\u043d\\u044b\\u0435\",\"indices\":[74,83]},{\"text\":\"\\u0441\\u043e\\u043d\",\"indices\":[84,88]},{\"text\":\"\\u043c\\u0438\\u043c\\u0438\\u043c\\u0438\",\"indices\":[89,96]},{\"text\":\"\\u043c\\u0438\\u043c\\u0438\\u0448\\u043d\\u043e\\u0441\\u0442\\u044c\",\"indices\":[97,108]},{\"text\":\"\\u0444\\u043e\\u0442\\u043e\",\"indices\":[109,114]}],\"urls\":[{\"url\":\"https:\\/\\/t.co\\/WFDmTgzIkM\",\"expanded_url\":\"http:\\/\\/nest.moscow\\/info\\/fotoworld\\/130-collections\\/407-sleeping\",\"display_url\":\"nest.moscow\\/info\\/fotoworld\\u2026\",\"indices\":[49,72]}],\"user_mentions\":[],\"symbols\":[],\"media\":[{\"id\":687355974143852544,\"id_str\":\"687355974143852544\",\"indices\":[115,138],\"media_url\":\"http:\\/\\/pbs.twimg.com\\/media\\/CYn6neEWQAA-AZo.jpg\",\"media_url_https\":\"https:\\/\\/pbs.twimg.com\\/media\\/CYn6neEWQAA-AZo.jpg\",\"url\":\"https:\\/\\/t.co\\/oZOBaUhCaw\",\"display_url\":\"pic.twitter.com\\/oZOBaUhCaw\",\"expanded_url\":\"http:\\/\\/twitter.com\\/nestmoscow\\/status\\/687355975200845824\\/photo\\/1\",\"type\":\"photo\",\"sizes\":{\"large\":{\"w\":800,\"h\":534,\"resize\":\"fit\"},\"medium\":{\"w\":600,\"h\":400,\"resize\":\"fit\"},\"thumb\":{\"w\":150,\"h\":150,\"resize\":\"crop\"},\"small\":{\"w\":340,\"h\":226,\"resize\":\"fit\"}}}]},\"extended_entities\":{\"media\":[{\"id\":687355974143852544,\"id_str\":\"687355974143852544\",\"indices\":[115,138],\"media_url\":\"http:\\/\\/pbs.twimg.com\\/media\\/CYn6neEWQAA-AZo.jpg\",\"media_url_https\":\"https:\\/\\/pbs.twimg.com\\/media\\/CYn6neEWQAA-AZo.jpg\",\"url\":\"https:\\/\\/t.co\\/oZOBaUhCaw\",\"display_url\":\"pic.twitter.com\\/oZOBaUhCaw\",\"expanded_url\":\"http:\\/\\/twitter.com\\/nestmoscow\\/status\\/687355975200845824\\/photo\\/1\",\"type\":\"photo\",\"sizes\":{\"large\":{\"w\":800,\"h\":534,\"resize\":\"fit\"},\"medium\":{\"w\":600,\"h\":400,\"resize\":\"fit\"},\"thumb\":{\"w\":150,\"h\":150,\"resize\":\"crop\"},\"small\":{\"w\":340,\"h\":226,\"resize\":\"fit\"}}}]},\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"ru\"},\"is_quote_status\":false,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[{\"text\":\"\\u0436\\u0438\\u0432\\u043e\\u0442\\u043d\\u044b\\u0435\",\"indices\":[90,99]},{\"text\":\"\\u0441\\u043e\\u043d\",\"indices\":[100,104]},{\"text\":\"\\u043c\\u0438\\u043c\\u0438\\u043c\\u0438\",\"indices\":[105,112]},{\"text\":\"\\u043c\\u0438\\u043c\\u0438\\u0448\\u043d\\u043e\\u0441\\u0442\\u044c\",\"indices\":[113,124]},{\"text\":\"\\u0444\\u043e\\u0442\\u043e\",\"indices\":[125,130]}],\"urls\":[{\"url\":\"https:\\/\\/t.co\\/WFDmTgzIkM\",\"expanded_url\":\"http:\\/\\/nest.moscow\\/info\\/fotoworld\\/130-collections\\/407-sleeping\",\"display_url\":\"nest.moscow\\/info\\/fotoworld\\u2026\",\"indices\":[65,88]}],\"user_mentions\":[{\"screen_name\":\"nestmoscow\",\"name\":\"\\u0413\\u043d\\u0435\\u0437\\u0434\\u044b\\u0448\\u043a\\u043e\",\"id\":3004102805,\"id_str\":\"3004102805\",\"indices\":[3,14]}],\"symbols\":[],\"media\":[{\"id\":687355974143852544,\"id_str\":\"687355974143852544\",\"indices\":[139,140],\"media_url\":\"http:\\/\\/pbs.twimg.com\\/media\\/CYn6neEWQAA-AZo.jpg\",\"media_url_https\":\"https:\\/\\/pbs.twimg.com\\/media\\/CYn6neEWQAA-AZo.jpg\",\"url\":\"https:\\/\\/t.co\\/oZOBaUhCaw\",\"display_url\":\"pic.twitter.com\\/oZOBaUhCaw\",\"expanded_url\":\"http:\\/\\/twitter.com\\/nestmoscow\\/status\\/687355975200845824\\/photo\\/1\",\"type\":\"photo\",\"sizes\":{\"large\":{\"w\":800,\"h\":534,\"resize\":\"fit\"},\"medium\":{\"w\":600,\"h\":400,\"resize\":\"fit\"},\"thumb\":{\"w\":150,\"h\":150,\"resize\":\"crop\"},\"small\":{\"w\":340,\"h\":226,\"resize\":\"fit\"}},\"source_status_id\":687355975200845824,\"source_status_id_str\":\"687355975200845824\",\"source_user_id\":3004102805,\"source_user_id_str\":\"3004102805\"}]},\"extended_entities\":{\"media\":[{\"id\":687355974143852544,\"id_str\":\"687355974143852544\",\"indices\":[139,140],\"media_url\":\"http:\\/\\/pbs.twimg.com\\/media\\/CYn6neEWQAA-AZo.jpg\",\"media_url_https\":\"https:\\/\\/pbs.twimg.com\\/media\\/CYn6neEWQAA-AZo.jpg\",\"url\":\"https:\\/\\/t.co\\/oZOBaUhCaw\",\"display_url\":\"pic.twitter.com\\/oZOBaUhCaw\",\"expanded_url\":\"http:\\/\\/twitter.com\\/nestmoscow\\/status\\/687355975200845824\\/photo\\/1\",\"type\":\"photo\",\"sizes\":{\"large\":{\"w\":800,\"h\":534,\"resize\":\"fit\"},\"medium\":{\"w\":600,\"h\":400,\"resize\":\"fit\"},\"thumb\":{\"w\":150,\"h\":150,\"resize\":\"crop\"},\"small\":{\"w\":340,\"h\":226,\"resize\":\"fit\"}},\"source_status_id\":687355975200845824,\"source_status_id_str\":\"687355975200845824\",\"source_user_id\":3004102805,\"source_user_id_str\":\"3004102805\"}]},\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"ru\",\"timestamp_ms\":\"1452713641652\"}\t\n687356954151366656\t1452713643001\tWed Jan 13 19:34:03 +0000 2016\tNews_Channel17\tmacbook pro หา External Hard drive ไม่เจอ ขึ้นชื่อจางๆ https://t.co/hshKVoWqwJ #pantip #News_channel17\t{\"created_at\":\"Wed Jan 13 19:34:03 +0000 2016\",\"id\":687356954151366656,\"id_str\":\"687356954151366656\",\"text\":\"macbook pro \\u0e2b\\u0e32 External Hard drive \\u0e44\\u0e21\\u0e48\\u0e40\\u0e08\\u0e2d \\u0e02\\u0e36\\u0e49\\u0e19\\u0e0a\\u0e37\\u0e48\\u0e2d\\u0e08\\u0e32\\u0e07\\u0e46 https:\\/\\/t.co\\/hshKVoWqwJ #pantip #News_channel17\",\"source\":\"\\u003ca href\u003d\\\"http:\\/\\/ifttt.com\\\" rel\u003d\\\"nofollow\\\"\\u003eIFTTT\\u003c\\/a\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":1933796366,\"id_str\":\"1933796366\",\"name\":\"\\u0e01\\u0e23\\u0e30\\u0e1a\\u0e2d\\u0e01\\u0e40\\u0e2a\\u0e35\\u0e22\\u0e07\",\"screen_name\":\"News_Channel17\",\"location\":\"Thailand\",\"url\":\"http:\\/\\/facebook.com\\/nc17th\",\"description\":\"Data \t\n687356970471325696\t1452713646892\tWed Jan 13 19:34:06 +0000 2016\t1977_ruka\t皆さんにお聞きします、Appleの商品で好きな製品を教えて下さい。自分のランキングはこうなります。1位　i MAC2位　i Pad Air23位　i Phone4位　Macbook Pro5位　i Pod Ｃｌａｓｓｉｃ＃拡散希望\t{\"created_at\":\"Wed Jan 13 19:34:06 +0000 2016\",\"id\":687356970471325696,\"id_str\":\"687356970471325696\",\"text\":\"\\u7686\\u3055\\u3093\\u306b\\u304a\\u805e\\u304d\\u3057\\u307e\\u3059\\u3001Apple\\u306e\\u5546\\u54c1\\u3067\\u597d\\u304d\\u306a\\u88fd\\u54c1\\u3092\\u6559\\u3048\\u3066\\u4e0b\\u3055\\u3044\\u3002\\u81ea\\u5206\\u306e\\u30e9\\u30f3\\u30ad\\u30f3\\u30b0\\u306f\\u3053\\u3046\\u306a\\u308a\\u307e\\u3059\\u3002\\n\\n1\\u4f4d\\u3000i MAC\\n2\\u4f4d\\u3000i Pad Air2\\n3\\u4f4d\\u3000i Phone\\n4\\u4f4d\\u3000Macbook Pro\\n5\\u4f4d\\u3000i Pod \\uff23\\uff4c\\uff41\\uff53\\uff53\\uff49\\uff43\\n\\n\\uff03\\u62e1\\u6563\\u5e0c\\u671b\",\"source\":\"\\u003ca href\u003d\\\"http:\\/\\/twittbot.net\\/\\\" rel\u003d\\\"nofollow\\\"\\u003etwittbot.net\\u003c\\/a\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":2952791384,\"id_str\":\"2952791384\",\"name\":\"\\u30c8\\u30ea\\u30d7\\u30eb\\u2b50\\ufe0f\",\"screen_name\":\"1977_ruka\",\"location\":\"\\u795e\\u5948\\u5ddd\\u770c\",\"url\":null,\"description\":\"\\u897f\\u5cf6\\u3001\\u5b87\\u91ce\\u3061\\u3083\\u3093\\u304c\\u5927\\u597d\\u304d\\u3067\\u3059\\u3002\\u305f\\u304b\\u3046\\u306e\\u63a8\\u3057\\u3067\\u3059\\u3002AAA\\u304c\\u597d\\u304d\\u306a\\u65b9\\u306f \\u30d5\\u30a9\\u30ed\\u30ef\\u30fc\\u3057\\u3066\\u4e0b\\u3055\\u308b\\u3068 \\u3042\\u308a\\u304c\\u305f\\u3044\\u3067\\u3059\\u3002 \\u30d5\\u30a1\\u30f3\\u6b74:2014\\u5e74\\u304b\\u3089\\u3067\\u3059\\u3002 LIVE\\u306f\\u307e\\u3060\\u672a\\u7d4c\\u9a13\\u3067\\u3059\\u3002\\u884c\\u304f\\u306e\\u304c\\u76ee\\u6a19\\u3067\\u3059\\u3002 (\\u6d66\\u7530\\u541b\\u3068\\u540c\\u3058\\u5e74\\u9f62\\u306e\\u7537\\u5b50\\u3067\\u3059)\",\"protected\":false,\"verified\":false,\"followers_count\":146,\"friends_count\":268,\"listed_count\":0,\"favourites_count\":769,\"statuses_count\":13576,\"created_at\":\"Tue Dec 30 23:59:45 +0000 2014\",\"utc_offset\":32400,\"time_zone\":\"Tokyo\",\"geo_enabled\":true,\"lang\":\"ja\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"89C9FA\",\"profile_background_image_url\":\"http:\\/\\/pbs.twimg.com\\/profile_background_images\\/646441672952274946\\/MaryRv9l.jpg\",\"profile_background_image_url_https\":\"https:\\/\\/pbs.twimg.com\\/profile_background_images\\/646441672952274946\\/MaryRv9l.jpg\",\"profile_background_tile\":false,\"profile_link_color\":\"3B94D9\",\"profile_sidebar_border_color\":\"C0DEED\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\/\\/pbs.twimg.com\\/profile_images\\/680651414146650112\\/A4IWOixm_normal.jpg\",\"profile_image_url_https\":\"https:\\/\\/pbs.twimg.com\\/profile_images\\/680651414146650112\\/A4IWOixm_normal.jpg\",\"profile_banner_url\":\"https:\\/\\/pbs.twimg.com\\/profile_banners\\/2952791384\\/1431518222\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[{\"text\":\"\\u62e1\\u6563\\u5e0c\\u671b\",\"indices\":[118,123]}],\"urls\":[],\"user_mentions\":[],\"symbols\":[]},\"favorited\":false,\"retweeted\":false,\"filter_level\":\"low\",\"lang\":\"ja\",\"timestamp_ms\":\"1452713646892\"}\t\n687356971264049153\t1452713647081\tWed Jan 13 19:34:07 +0000 2016\tgomaam\t6 problems with the #LGV10 and #howto fix them https://t.co/gxTiYuMjbL\t{\"created_at\":\"Wed Jan 13 19:34:07 +0000 2016\",\"id\":687356971264049153,\"id_str\":\"687356971264049153\",\"text\":\"6 problems with the #LGV10 and #howto fix them https:\\/\\/t.co\\/gxTiYuMjbL\",\"source\":\"\\u003ca href\u003d\\\"http:\\/\\/dlvr.it\\\" rel\u003d\\\"nofollow\\\"\\u003edlvr.it\\u003c\\/a\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":16795287,\"id_str\":\"16795287\",\"name\":\"gomaam\",\"screen_name\":\"gomaam\",\"location\":\"always on the move.....\",\"url\":null,\"description\":\"I love gadgets and technology always want the latest..Love cars and travel! Always remember take it and go..Tomorrow is a new day? Follow me... follow you....\",\"protected\":false,\"verified\":false,\"followers_count\":4557,\"friends_count\":4550,\"listed_count\":657,\"favourites_count\":15,\"statuses_count\":624443,\"created_at\":\"Wed Oct 15 21:58:00 +0000 2008\",\"utc_offset\":-28800,\"time_zone\":\"Pacific Time (US \u0026 Canada)\",\"geo_enabled\":true,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"352726\",\"profile_background_image_url\":\"http:\\/\\/abs.twimg.com\\/images\\/themes\\/theme5\\/bg.gif\",\"profile_background_image_url_https\":\"https:\\/\\/abs.twimg.com\\/images\\/themes\\/theme5\\/bg.gif\",\"profile_background_tile\":false,\"profile_link_color\":\"D02B55\",\"profile_sidebar_border_color\":\"829D5E\",\"profile_sidebar_fill_color\":\"99CC33\",\"profile_text_color\":\"3E4415\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\/\\/pbs.twimg.com\\/profile_images\\/644391623204343808\\/d3x9-b9T_normal.jpg\",\"profile_image_url_https\":\"https:\\/\\/pbs.twimg.com\\/profile_images\\/644391623204343808\\/d3x9-b9T_normal.jpg\",\"profile_banner_url\":\"https:\\/\\/pbs.twimg.com\\/profile_banners\\/16795287\\/1365622044\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[{\"text\":\"LGV10\",\"indices\":[20,26]},{\"text\":\"howto\",\"indices\":[31,37]}],\"urls\":[{\"url\":\"https:\\/\\/t.co\\/gxTiYuMjbL\",\"expanded_url\":\"http:\\/\\/dlvr.it\\/DGR4nx\",\"display_url\":\"dlvr.it\\/DGR4nx\",\"indices\":[47,70]}],\"user_mentions\":[],\"symbols\":[]},\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"en\",\"timestamp_ms\":\"1452713647081\"}\t\n687356972203544576\t1452713647305\tWed Jan 13 19:34:07 +0000 2016\tCellShop15\tType C, USB 2.0 iOrange-E™10ft (3M)Braided Cable for 2015 New Macbook 12\u0027\u0027, ChromeBook Pixel, OnePlus 2, Nexus 6P,… https://t.co/Lo2FZpq3yI\t{\"created_at\":\"Wed Jan 13 19:34:07 +0000 2016\",\"id\":687356972203544576,\"id_str\":\"687356972203544576\",\"text\":\"Type C, USB 2.0 iOrange-E\\u212210ft (3M)Braided Cable for 2015 New Macbook 12\u0027\u0027, ChromeBook Pixel, OnePlus 2, Nexus 6P,\\u2026 https:\\/\\/t.co\\/Lo2FZpq3yI\",\"source\":\"\\u003ca href\u003d\\\"http:\\/\\/dlvr.it\\\" rel\u003d\\\"nofollow\\\"\\u003edlvr.it\\u003c\\/a\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":3710490751,\"id_str\":\"3710490751\",\"name\":\"Cell Shop\",\"screen_name\":\"CellShop15\",\"location\":\"US\",\"url\":null,\"description\":\"Buy the latest mobiles and cell phones with the best technology, new releases and launches\",\"protected\":false,\"verified\":false,\"followers_count\":4,\"friends_count\":0,\"listed_count\":1,\"favourites_count\":0,\"statuses_count\":43403,\"created_at\":\"Mon Sep 28 03:22:06 +0000 2015\",\"utc_offset\":null,\"time_zone\":null,\"geo_enabled\":false,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"131516\",\"profile_background_image_url\":\"http:\\/\\/abs.twimg.com\\/images\\/themes\\/theme14\\/bg.gif\",\"profile_background_image_url_https\":\"https:\\/\\/abs.twimg.com\\/images\\/themes\\/theme14\\/bg.gif\",\"profile_background_tile\":true,\"profile_link_color\":\"009999\",\"profile_sidebar_border_color\":\"EEEEEE\",\"profile_sidebar_fill_color\":\"EFEFEF\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\/\\/pbs.twimg.com\\/profile_images\\/648337589578018817\\/LI0dlQs6_normal.jpg\",\"profile_image_url_https\":\"https:\\/\\/pbs.twimg.com\\/profile_images\\/648337589578018817\\/LI0dlQs6_normal.jpg\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[],\"urls\":[{\"url\":\"https:\\/\\/t.co\\/Lo2FZpq3yI\",\"expanded_url\":\"http:\\/\\/www.amazon.com\\/iOrange-E-Braided-Macbook-ChromeBook-OnePlus\\/dp\\/B016ZYUG80\\/ref\u003dpd_zg_rss_ms_cps_wireless_8?ie\u003dUTF8\u0026tag\u003dshopping08a7-20\",\"display_url\":\"amazon.com\\/iOrange-E-Brai\\u2026\",\"indices\":[116,139]}],\"user_mentions\":[],\"symbols\":[]},\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"en\",\"timestamp_ms\":\"1452713647305\"}\t\n"
      },
      "dateCreated": "Jan 13, 2016 7:37:19 PM",
      "dateStarted": "Jan 13, 2016 9:10:32 PM",
      "dateFinished": "Jan 13, 2016 9:10:34 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\ncreate table if not exists weblog(\n  clickid string,    \n  session int, \n  userid int, \n  visited timestamp, \n  product string\n)\nrow format delimited fields terminated by \",\"\nlocation \"/tmp/weblog_staging\"",
      "dateUpdated": "Jan 13, 2016 11:52:55 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452713932897_-2124663831",
      "id": "20160113-193852_41019454",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 7:38:52 PM",
      "dateStarted": "Jan 13, 2016 11:52:55 PM",
      "dateFinished": "Jan 13, 2016 11:52:56 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nselect * from weblog limit 5",
      "dateUpdated": "Jan 13, 2016 11:52:59 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452729023043_911222965",
      "id": "20160113-235023_891487368",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "weblog.clickid\tweblog.session\tweblog.userid\tweblog.visited\tweblog.product\n1-2\t2\t2\t2007-06-12 00:16:10.0\tLG G Stylo\t\n2-2\t2\t2\t2007-06-12 00:17:54.0\tLenovo Yoga 900\t\n3-2\t2\t2\t2007-06-12 00:18:43.0\tFitbit Charge HR\t\n4-2\t2\t2\t2007-06-12 00:20:27.0\tAmazon Kindle Paperwhite (2015)\t\n5-2\t2\t2\t2007-06-12 00:23:23.0\tLG V10 (unlocked)\t\n"
      },
      "dateCreated": "Jan 13, 2016 11:50:23 PM",
      "dateStarted": "Jan 13, 2016 11:52:59 PM",
      "dateFinished": "Jan 13, 2016 11:53:01 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nselect count(distinct session) from weblog",
      "dateUpdated": "Jan 13, 2016 11:53:10 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452717687969_-780406490",
      "id": "20160113-204127_35708745",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "c0\n9\t\n"
      },
      "dateCreated": "Jan 13, 2016 8:41:27 PM",
      "dateStarted": "Jan 13, 2016 11:53:10 PM",
      "dateFinished": "Jan 13, 2016 11:53:37 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Step 4: Analyze tables/columns\n\nNow lets analyze the tables we are interested in\n",
      "dateUpdated": "Jan 13, 2016 10:28:31 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452721433491_1920109337",
      "id": "20160113-214353_719128300",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4\u003eStep 4: Analyze tables/columns\u003c/h4\u003e\n\u003cp\u003eNow lets analyze the tables we are interested in\u003c/p\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 9:43:53 PM",
      "dateStarted": "Jan 13, 2016 10:28:29 PM",
      "dateFinished": "Jan 13, 2016 10:28:30 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nanalyze table tweets compute statistics",
      "dateUpdated": "Jan 13, 2016 10:21:14 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452717815305_-1694384342",
      "id": "20160113-204335_1874970606",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 8:43:35 PM",
      "dateStarted": "Jan 13, 2016 10:21:14 PM",
      "dateFinished": "Jan 13, 2016 10:21:36 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nanalyze table weblog compute statistics",
      "dateUpdated": "Jan 13, 2016 11:53:43 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452721373956_1663020451",
      "id": "20160113-214253_1051568440",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 9:42:53 PM",
      "dateStarted": "Jan 13, 2016 11:53:43 PM",
      "dateFinished": "Jan 13, 2016 11:53:47 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nanalyze table factsales_final compute statistics",
      "dateUpdated": "Jan 13, 2016 10:21:29 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452721472392_1433279385",
      "id": "20160113-214432_1363478432",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 9:44:32 PM",
      "dateStarted": "Jan 13, 2016 10:21:37 PM",
      "dateFinished": "Jan 13, 2016 10:21:43 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nNext lets compute column statistics for the same tables",
      "dateUpdated": "Jan 13, 2016 10:22:04 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452723689940_661502389",
      "id": "20160113-222129_1782182444",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eNext lets compute column statistics for the same tables\u003c/p\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 10:21:29 PM",
      "dateStarted": "Jan 13, 2016 10:22:02 PM",
      "dateFinished": "Jan 13, 2016 10:22:05 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nanalyze table tweets compute statistics for columns",
      "dateUpdated": "Jan 13, 2016 10:22:27 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452723717803_-2109413217",
      "id": "20160113-222157_507284179",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 10:21:57 PM",
      "dateStarted": "Jan 13, 2016 10:22:27 PM",
      "dateFinished": "Jan 13, 2016 10:22:37 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nanalyze table weblog compute statistics for columns",
      "dateUpdated": "Jan 13, 2016 11:53:48 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452723747762_-1218872755",
      "id": "20160113-222227_1514449570",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 10:22:27 PM",
      "dateStarted": "Jan 13, 2016 11:53:48 PM",
      "dateFinished": "Jan 13, 2016 11:53:52 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nanalyze table factsales_final compute statistics for columns",
      "dateUpdated": "Jan 13, 2016 10:23:10 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452723767145_-631699961",
      "id": "20160113-222247_186145308",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 13, 2016 10:22:47 PM",
      "dateStarted": "Jan 13, 2016 10:23:10 PM",
      "dateFinished": "Jan 13, 2016 10:24:12 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Step 5: Use Hive to correlate the data from different sources\n\n##### Query A: Most visited product query",
      "dateUpdated": "Jan 13, 2016 10:34:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452723790574_-1153004072",
      "id": "20160113-222310_1267394170",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4\u003eStep 5: Use Hive to correlate the data from different sources\u003c/h4\u003e\n\u003ch5\u003eQuery A: Most visited product query\u003c/h5\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 10:23:10 PM",
      "dateStarted": "Jan 13, 2016 10:34:19 PM",
      "dateFinished": "Jan 13, 2016 10:34:19 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nselect product,count(1) popular \nfrom weblog group by product order by popular desc limit 10",
      "dateUpdated": "Jan 14, 2016 4:05:55 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "product",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "popular",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "product",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "popular",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452724190719_-2066998893",
      "id": "20160113-222950_1405982278",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "product\tpopular\nNest Learning Thermostat\t5\t\nTCL S3800 series (Roku TV\t3\t\nSamsung Galaxy S6 Edge+\t3\t\niPad Mini 2\t2\t\nAmazon Kindle Paperwhite (2015)\t2\t\nApple iPhone 5S\t2\t\nRoku 4\t2\t\niPad Air 2\t2\t\nLG G Stylo\t2\t\nApple iPhone 5\t2\t\n"
      },
      "dateCreated": "Jan 13, 2016 10:29:50 PM",
      "dateStarted": "Jan 14, 2016 4:05:55 AM",
      "dateFinished": "Jan 14, 2016 4:06:12 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n##### Query B: Top products with most time spent by year",
      "dateUpdated": "Jan 13, 2016 10:35:03 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452724362356_1428104444",
      "id": "20160113-223242_148647850",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch5\u003eQuery B: Top products with most time spent by year\u003c/h5\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 10:32:42 PM",
      "dateStarted": "Jan 13, 2016 10:35:00 PM",
      "dateFinished": "Jan 13, 2016 10:35:01 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nselect product,year_visited, sum(time_spent) as total_time from\n(select table1.product,year(visited) as year_visited, \nmonth(visited) as month,unix_timestamp(table1.lead_window_0) - unix_timestamp(table1.visited) as time_spent\nfrom (select product,visited,lead(visited)  over (PARTITION BY session ORDER BY visited asc) from weblog) table1 \nwhere table1.lead_window_0 is not NULL) table2\ngroup by product,year_visited \norder by total_time desc limit 100",
      "dateUpdated": "Jan 14, 2016 4:07:26 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "product",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "total_time",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "product",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "year_visited",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452724500772_-1601453844",
      "id": "20160113-223500_319311539",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "product\tyear_visited\ttotal_time\nApple iPhone 5\t2009\t431\t\nHP Spectre x360\t2008\t226\t\nMotorola Droid Turbo 2\t2009\t225\t\nApple iPhone 5S\t2009\t223\t\nSamsung Galaxy Core Prime\t2008\t220\t\nSimpliSafe Home Security\t2009\t218\t\nVizio E series (2015)\t2008\t215\t\nNest Learning Thermostat\t2008\t206\t\nApple iPhone 6S\t2008\t194\t\nTCL S3800 series (Roku TV\t2009\t192\t\nLG G Stylo\t2008\t186\t\nSamsung UNJU7100 series\t2008\t185\t\nTCL S3800 series (Roku TV\t2007\t184\t\nSamsung Galaxy S6 Edge+\t2008\t181\t\nSamsung UNJS8500 series\t2007\t177\t\nAmazon Kindle Paperwhite (2015)\t2007\t176\t\niPad Air 2\t2009\t169\t\nGoogle Nexus 5X\t2007\t167\t\nBeats Studio Wireless Headphones\t2007\t167\t\nGoPro Hero3\t2008\t166\t\nSamsung Gear VR (2015)\t2007\t163\t\nLG V10 (unlocked)\t2007\t160\t\nHTC One M9\t2009\t160\t\nAmazon Kindle Paperwhite (2015)\t2008\t159\t\nSimpliSafe Home Security\t2007\t158\t\nTCL FS4610R (Roku TV)\t2008\t154\t\nSamsung Gear VR (2015)\t2008\t150\t\nSamsung Galaxy Grand Prime\t2009\t145\t\nHP Stream 11\t2009\t143\t\nSennheiser Momentum 2.0\t2009\t140\t\nSamsung Galaxy S6 Edge\t2008\t138\t\nSamsung Galaxy S5\t2009\t137\t\nBose SoundLink Around-Ear Wireless Headphones II\t2009\t134\t\nRoku 4\t2009\t128\t\nApple iPad Mini 4\t2009\t127\t\nSony Xperia Z5\t2009\t125\t\nMicrosoft Surface Pro 4\t2008\t118\t\nTiVo Bolt\t2009\t118\t\nHTC One M9\t2007\t109\t\niPad Pro\t2009\t108\t\nLG G Stylo\t2007\t104\t\nFitbit Charge HR\t2007\t104\t\nTCL FS4610R (Roku TV)\t2009\t102\t\nSamsung Gear S2\t2008\t91\t\nApple MacBook Pro with Retina Display (13-inch\t2007\t87\t\nSamsung Galaxy S6\t2009\t82\t\nAsus Chromebit\t2007\t80\t\nApple CarPlay\t2009\t79\t\nApple iPhone 5S\t2007\t76\t\niPad Air 2\t2007\t68\t\nSamsung SSD 850 Evo\t2008\t66\t\nNest Learning Thermostat\t2007\t66\t\nSennheiser HD 598\t2009\t59\t\niPad Mini 2\t2008\t57\t\nLenovo Yoga 900\t2007\t49\t\nBeats Solo 2\t2009\t40\t\nNinja Coffee Bar\t2008\t37\t\nBeats Powerbeats2 Wireless\t2009\t33\t\nSony Alpha 6000 (ILCE-6000)\t2008\t32\t\nVizio E series (2015)\t2009\t30\t\n"
      },
      "dateCreated": "Jan 13, 2016 10:35:00 PM",
      "dateStarted": "Jan 14, 2016 4:07:26 AM",
      "dateFinished": "Jan 14, 2016 4:07:35 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n##### Query C - most popular web_path \n\nTODO: further improvement to analyze paths of minimum length",
      "dateUpdated": "Jan 13, 2016 10:46:27 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452724536034_371815995",
      "id": "20160113-223536_1474440938",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch5\u003eQuery C - most popular web_path\u003c/h5\u003e\n\u003cp\u003eTODO: further improvement to analyze paths of minimum length\u003c/p\u003e\n"
      },
      "dateCreated": "Jan 13, 2016 10:35:36 PM",
      "dateStarted": "Jan 13, 2016 10:46:14 PM",
      "dateFinished": "Jan 13, 2016 10:46:16 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nselect web_path,count(1) as path_count\nfrom\n(select session,concat_ws(\"-\u003e\",collect_list(product)) as web_path\nfrom weblog group by session) table1\ngroup by web_path\norder by path_count desc",
      "dateUpdated": "Jan 13, 2016 11:55:03 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452725174403_1648549119",
      "id": "20160113-224614_841055273",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "web_path\tpath_count\nAsus Chromebit-\u003eNest Learning Thermostat-\u003eTCL S3800 series (Roku TV-\u003eBose QuietComfort 25\t1\t\nHP Stream 11-\u003eBeats Solo 2-\u003eiPad Air 2-\u003eApple iPad Mini 4-\u003eApple iPhone 5-\u003eApple CarPlay-\u003eSamsung Galaxy S5-\u003eiPad Pro-\u003eTiVo Bolt-\u003eGoPro Hero3\t1\t\nHTC One M9-\u003eSamsung UNJS8500 series-\u003eApple iPhone 5S-\u003eNest Learning Thermostat-\u003eTCL S3800 series (Roku TV-\u003eBeats Studio Wireless Headphones-\u003eGoogle Nexus 5X-\u003eApple MacBook Pro with Retina Display (13-inch-\u003eiPad Mini 2\t1\t\nLG G Stylo-\u003eLenovo Yoga 900-\u003eFitbit Charge HR-\u003eAmazon Kindle Paperwhite (2015)-\u003eLG V10 (unlocked)-\u003eiPad Air 2-\u003eSamsung Gear VR (2015)-\u003eSimpliSafe Home Security-\u003eSamsung Gear S2\t1\t\nMotorola Droid Turbo 2-\u003eSimpliSafe Home Security-\u003eSony Xperia Z5-\u003eTCL FS4610R (Roku TV)-\u003eBeats Powerbeats2 Wireless-\u003eBose SoundLink Around-Ear Wireless Headphones II-\u003eHTC One M9-\u003eApple iPhone 5-\u003eSennheiser Momentum 2.0-\u003eSamsung Galaxy S6 Edge+\t1\t\nNest Learning Thermostat-\u003eSamsung Galaxy S6 Edge+-\u003eSamsung Galaxy S6 Edge-\u003eSamsung Galaxy S6 Edge+-\u003eHP Spectre x360-\u003eNest Learning Thermostat-\u003eSamsung Galaxy Core Prime-\u003eVizio E series (2015)-\u003eSamsung SSD 850 Evo-\u003eNest Learning Thermostat\t1\t\nRoku 4-\u003eRoku 4-\u003eApple iPhone 5S-\u003eSamsung Galaxy Grand Prime-\u003eSamsung Galaxy S6-\u003eVizio E series (2015)-\u003eSennheiser HD 598-\u003eTCL S3800 series (Roku TV-\u003eMicrosoft Surface Book\t1\t\nSamsung Gear VR (2015)-\u003eLG G Stylo-\u003eGoPro Hero3-\u003eMicrosoft Surface Pro 4-\u003eNinja Coffee Bar\t1\t\nSony Alpha 6000 (ILCE-6000)-\u003eNinja Coffee Bar-\u003eSamsung Gear S2-\u003eApple iPhone 6S-\u003eAmazon Kindle Paperwhite (2015)-\u003eSamsung UNJU7100 series-\u003eTCL FS4610R (Roku TV)-\u003eiPad Mini 2-\u003eUE Boom 2\t1\t\n"
      },
      "dateCreated": "Jan 13, 2016 10:46:14 PM",
      "dateStarted": "Jan 13, 2016 11:55:03 PM",
      "dateFinished": "Jan 13, 2016 11:55:11 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\nwget https://github.com/hortonworks-gallery/hdp22-twitter-demo/raw/master/dictionary/dictionary.csv -P /tmp",
      "dateUpdated": "Jan 14, 2016 3:50:41 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452725205067_-1225125092",
      "id": "20160113-224645_1310572979",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "--2016-01-14 03:50:43--  https://github.com/hortonworks-gallery/hdp22-twitter-demo/raw/master/dictionary/dictionary.csv\nResolving github.com... 192.30.252.129\nConnecting to github.com|192.30.252.129|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/hortonworks-gallery/hdp22-twitter-demo/master/dictionary/dictionary.csv [following]\n--2016-01-14 03:50:45--  https://raw.githubusercontent.com/hortonworks-gallery/hdp22-twitter-demo/master/dictionary/dictionary.csv\nResolving raw.githubusercontent.com... 23.235.39.133\nConnecting to raw.githubusercontent.com|23.235.39.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 126158 (123K) [text/plain]\nSaving to: “/tmp/dictionary.csv”\n\n     0K .......... .......... .......... .......... .......... 40%  668K 0s\n    50K .......... .......... .......... .......... .......... 81%  302K 0s\n   100K .......... .......... ...                             100% 4.96M\u003d0.2s\n\n2016-01-14 03:50:46 (502 KB/s) - “/tmp/dictionary.csv” saved [126158/126158]\n\n"
      },
      "dateCreated": "Jan 13, 2016 10:46:45 PM",
      "dateStarted": "Jan 14, 2016 3:50:41 AM",
      "dateFinished": "Jan 14, 2016 3:50:46 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nCREATE TABLE dictionary (\nword string ,\nsentiment string\n)\nROW FORMAT DELIMITED FIELDS TERMINATED BY \u0027,\u0027 STORED AS TextFile",
      "dateUpdated": "Jan 14, 2016 3:55:58 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452742977552_746391295",
      "id": "20160114-034257_1515158976",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 14, 2016 3:42:57 AM",
      "dateStarted": "Jan 14, 2016 3:55:58 AM",
      "dateFinished": "Jan 14, 2016 3:56:01 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%hive\nload data local inpath \u0027/tmp/dictionary.csv\u0027 into table dictionary",
      "dateUpdated": "Jan 14, 2016 3:56:02 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452743642135_1249948219",
      "id": "20160114-035402_600791877",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "The query did not generate a result set!"
      },
      "dateCreated": "Jan 14, 2016 3:54:02 AM",
      "dateStarted": "Jan 14, 2016 3:56:03 AM",
      "dateFinished": "Jan 14, 2016 3:56:04 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452743693244_-474234196",
      "id": "20160114-035453_1657563174",
      "dateCreated": "Jan 14, 2016 3:54:53 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Single view demo",
  "id": "2BBBW75VS",
  "angularObjects": {
    "2B9QFS7JF": [],
    "2BA9W43AE": [],
    "2B8BP2VTR": [],
    "2B9695PC2": [],
    "2B8FBNTHB": [],
    "2BBJJJF7Q": [],
    "2BB6D55KZ": [],
    "2B95M9AGR": [],
    "2BBJ623KJ": [],
    "2B9CTUJMG": [],
    "2BBF69APK": [],
    "2B8UU1EG1": [],
    "2BABR24NG": [],
    "2BBE1EKD1": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}